
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Tony Chou's Blog</title>
  <meta name="author" content="yoyzhou">

  
  <meta name="description" content="上一篇文章Hadoop序列化与Writable接口（一）介绍了Hadoop序列化，Hadoop Writable接口以及如何定制自己的Writable类，在本文中我们继续Hadoop Writable类的介绍，这一次我们关注的是Writable实例序列化之后占用的字节长度， &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://yoyzhou.github.com/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
   <link href="/stylesheets/data-table.css" media="screen, projection" rel="stylesheet" type="text/css" />
  <script src="/javascripts/modernizr-2.0.js"></script>
<!--
<script src="/javascripts/MathJax.js" type="text/javascript"></script>

<script src="http://kramdown.rubyforge.org/MathJax/MathJax.js" type="text/javascript"></script>
--!>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
	      jax: ["input/TeX", "output/HTML-CSS"],
		  tex2jax: {
		  inlineMath: [ ['$', '$'], ["\\(", "\\)"] ],
		  displayMath: [ ['$$', '$$'], ["\\[", "\\]"] ],
		  processEscapes: true,
		  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
		}}
   );
																			</script>
																			<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>

<script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/atom.xml" rel="alternate" title="Tony Chou's Blog" type="application/atom+xml">

  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>


  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-34034666-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
</hgroup>

</header>
  <!-- <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:yoyzhou.github.com" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav> -->
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/05/10/hadoop-serialization-and-writable-object-2/">Hadoop序列化与Writable接口(二)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-05-10T20:56:00+08:00" pubdate data-updated="true">May 10<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/05/10/hadoop-serialization-and-writable-object-2/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>上一篇文章<a href="/blog/2013/05/09/hadoop-serialization-and-writable-object-1/">Hadoop序列化与Writable接口（一）</a>介绍了Hadoop序列化，Hadoop Writable接口以及如何定制自己的Writable类，在本文中我们继续Hadoop Writable类的介绍，这一次我们关注的是Writable实例序列化之后占用的字节长度，以及Writable实例序列化之后的字节序列结构。</p>

<h4 id="writable">为什么要考虑Writable类的字节长度</h4>

<p>大数据程序还需要考虑序列化对象占用磁盘空间的大小吗？也许你会认为<strong>大数据</strong>不是就是数据量很大吗，那磁盘空间一定是足够足够的大，一个序列化对象仅仅占用几个到几十个字节的空间，相对磁盘空间来说，当然是不需要考虑太多；如果你的磁盘空间不够大，还是不要玩大数据的好。</p>

<p>上面的观点没有什么问题，大数据应用自然需要足够的磁盘空间，但是能够尽量的考虑到不同Writable类占用磁盘空间的大小，高效的利用磁盘空间也未必就是没有必要的，选择适当的Writable类的另一个作用是<strong>通过减少Writable实例的字节数，可加快数据的读取和减少网络的数据传输。</strong></p>

<h4 id="writable-1">Writable类占用的字节长度</h4>

<p>下面的表格显示的是Hadoop对Java基本类型包装后相应的Writable类占用的字节长度：</p>

<table>
  <tbody>
    <tr>
      <td>Java基本类型</td>
      <td>Writable实现</td>
      <td>序列化后字节数 (bytes)</td>
    </tr>
    <tr>
      <td>boolean</td>
      <td>BooleanWritable</td>
      <td>1</td>
    </tr>
    <tr>
      <td>byte</td>
      <td>ByteWritable</td>
      <td>1</td>
    </tr>
    <tr>
      <td>short</td>
      <td>ShortWritable</td>
      <td>2</td>
    </tr>
    <tr>
      <td>int</td>
      <td>IntWritable</td>
      <td>4</td>
    </tr>
    <tr>
      <td> </td>
      <td>VIntWritable</td>
      <td>1–5</td>
    </tr>
    <tr>
      <td>float</td>
      <td>FloatWritable</td>
      <td>4</td>
    </tr>
    <tr>
      <td>long</td>
      <td>LongWritable</td>
      <td>8</td>
    </tr>
    <tr>
      <td> </td>
      <td>VLongWritable</td>
      <td>1–9</td>
    </tr>
    <tr>
      <td>double</td>
      <td>DoubleWritable</td>
      <td>8</td>
    </tr>
  </tbody>
</table>

<p>不同的Writable类序列化后占用的字数长度是不一样的，需要综合考虑应用中数据特征选择合适的类型。对于整数类型有两种Writable类型可以选择，一种是定长（fixed-length）Writable类型,IntWritable和LongWritable；另一种是变长（variable-length）Writable类型，VIntWritable和VLongWritable。定长类型顾名思义使用固定长度的字节数表示，比如一个IntWritable类型使用4个长度的字节表示一个int；变长类型则根据数值的大小使用相应的字节长度表示，当数值在-127～127之间时使用1个字节表示，在-112～127范围之外的数值使用头一个字节表示该数值的正负符号以及字节长度（zero-compressed encoded integer）。</p>

<p>定长的Writable类型适合数值均匀分布的情形，而变长的Writable类型适合数值分布不均匀的情形，一般情况下变长的Writable类型更节省空间，因为大多数情况下数值是不均匀的，对于整数类型的Writable选择，我建议：</p>

<blockquote>
  <p>1. 除非对数据的均匀分布很有把握，否则使用变长Writable类型</p>
</blockquote>

<blockquote>
  <p>2. 除非数据的取值区间确定在int范围之内，否则为了程序的可扩展性，请选择VLongWritable类型</p>
</blockquote>

<h4 id="writable-2">整型Writable的字节序列</h4>

<p>下面将以实例的方式演示Hadoop整型Writable对象占用的字节长度以及Writable对象序列化之后字节序列的结构，特别是变长整型Writable实例，请看下面的代码和程序输出：</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
<span class="line-number">39</span>
<span class="line-number">40</span>
<span class="line-number">41</span>
<span class="line-number">42</span>
<span class="line-number">43</span>
<span class="line-number">44</span>
<span class="line-number">45</span>
<span class="line-number">46</span>
<span class="line-number">47</span>
<span class="line-number">48</span>
<span class="line-number">49</span>
<span class="line-number">50</span>
<span class="line-number">51</span>
<span class="line-number">52</span>
<span class="line-number">53</span>
<span class="line-number">54</span>
<span class="line-number">55</span>
<span class="line-number">56</span>
<span class="line-number">57</span>
<span class="line-number">58</span>
<span class="line-number">59</span>
<span class="line-number">60</span>
<span class="line-number">61</span>
<span class="line-number">62</span>
<span class="line-number">63</span>
<span class="line-number">64</span>
<span class="line-number">65</span>
<span class="line-number">66</span>
<span class="line-number">67</span>
<span class="line-number">68</span>
<span class="line-number">69</span>
<span class="line-number">70</span>
<span class="line-number">71</span>
<span class="line-number">72</span>
<span class="line-number">73</span>
<span class="line-number">74</span>
<span class="line-number">75</span>
<span class="line-number">76</span>
<span class="line-number">77</span>
<span class="line-number">78</span>
<span class="line-number">79</span>
<span class="line-number">80</span>
<span class="line-number">81</span>
<span class="line-number">82</span>
<span class="line-number">83</span>
<span class="line-number">84</span>
<span class="line-number">85</span>
<span class="line-number">86</span>
</pre></td><td class="code"><pre><code class="java"><span class="line"><span class="kn">package</span> <span class="n">com</span><span class="o">.</span><span class="na">yoyzhou</span><span class="o">.</span><span class="na">example</span><span class="o">;</span>
</span><span class="line">
</span><span class="line"><span class="kn">import</span> <span class="nn">java.io.*</span><span class="o">;</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">org.apache.hadoop.io.*</span><span class="o">;</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">org.apache.hadoop.util.StringUtils</span><span class="o">;</span>
</span><span class="line">
</span><span class="line"><span class="cm">/**</span>
</span><span class="line"><span class="cm"> * Demos per how many bytes per each built-in Writable type takes and what does</span>
</span><span class="line"><span class="cm"> * their bytes sequences look like</span>
</span><span class="line"><span class="cm"> * </span>
</span><span class="line"><span class="cm"> * @author yoyzhou</span>
</span><span class="line"><span class="cm"> * </span>
</span><span class="line"><span class="cm"> */</span>
</span><span class="line">
</span><span class="line"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">WritableBytesLengthDemo</span> <span class="o">{</span>
</span><span class="line">
</span><span class="line">	<span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
</span><span class="line">
</span><span class="line">		<span class="c1">// one billion representations by different Writable object</span>
</span><span class="line">		<span class="n">IntWritable</span> <span class="n">int_b</span> <span class="o">=</span> <span class="k">new</span> <span class="n">IntWritable</span><span class="o">(</span><span class="mi">1000000000</span><span class="o">);</span>
</span><span class="line">		<span class="n">LongWritable</span> <span class="n">long_b</span> <span class="o">=</span> <span class="k">new</span> <span class="n">LongWritable</span><span class="o">(</span><span class="mi">1000000000</span><span class="o">);</span>
</span><span class="line">		<span class="n">VIntWritable</span> <span class="n">vint_b</span> <span class="o">=</span> <span class="k">new</span> <span class="n">VIntWritable</span><span class="o">(</span><span class="mi">1000000000</span><span class="o">);</span>
</span><span class="line">		<span class="n">VLongWritable</span> <span class="n">vlong_b</span> <span class="o">=</span> <span class="k">new</span> <span class="n">VLongWritable</span><span class="o">(</span><span class="mi">1000000000</span><span class="o">);</span>
</span><span class="line">
</span><span class="line">		<span class="c1">// serialize writable object to byte array</span>
</span><span class="line">		<span class="kt">byte</span><span class="o">[]</span> <span class="n">bs_int_b</span> <span class="o">=</span> <span class="n">serialize</span><span class="o">(</span><span class="n">int_b</span><span class="o">);</span>
</span><span class="line">		<span class="kt">byte</span><span class="o">[]</span> <span class="n">bs_long_b</span> <span class="o">=</span> <span class="n">serialize</span><span class="o">(</span><span class="n">long_b</span><span class="o">);</span>
</span><span class="line">		<span class="kt">byte</span><span class="o">[]</span> <span class="n">bs_vint_b</span> <span class="o">=</span> <span class="n">serialize</span><span class="o">(</span><span class="n">vint_b</span><span class="o">);</span>
</span><span class="line">		<span class="kt">byte</span><span class="o">[]</span> <span class="n">bs_vlong_b</span> <span class="o">=</span> <span class="n">serialize</span><span class="o">(</span><span class="n">vlong_b</span><span class="o">);</span>
</span><span class="line">
</span><span class="line">		<span class="c1">// print byte array in hex string and their length</span>
</span><span class="line">		<span class="n">String</span> <span class="n">hex</span> <span class="o">=</span> <span class="n">StringUtils</span><span class="o">.</span><span class="na">byteToHexString</span><span class="o">(</span><span class="n">bs_int_b</span><span class="o">);</span>
</span><span class="line">		<span class="n">formatPrint</span><span class="o">(</span><span class="s">&quot;IntWritable&quot;</span><span class="o">,</span> <span class="s">&quot;1,000,000,000&quot;</span><span class="o">,</span><span class="n">hex</span><span class="o">,</span> <span class="n">bs_int_b</span><span class="o">.</span><span class="na">length</span><span class="o">);</span>
</span><span class="line">
</span><span class="line">		<span class="n">hex</span> <span class="o">=</span> <span class="n">StringUtils</span><span class="o">.</span><span class="na">byteToHexString</span><span class="o">(</span><span class="n">bs_long_b</span><span class="o">);</span>
</span><span class="line">		<span class="n">formatPrint</span><span class="o">(</span><span class="s">&quot;LongWritable&quot;</span><span class="o">,</span> <span class="s">&quot;1,000,000,000&quot;</span><span class="o">,</span><span class="n">hex</span><span class="o">,</span> <span class="n">bs_long_b</span><span class="o">.</span><span class="na">length</span><span class="o">);</span>
</span><span class="line">
</span><span class="line">		<span class="n">hex</span> <span class="o">=</span> <span class="n">StringUtils</span><span class="o">.</span><span class="na">byteToHexString</span><span class="o">(</span><span class="n">bs_vint_b</span><span class="o">);</span>
</span><span class="line">		<span class="n">formatPrint</span><span class="o">(</span><span class="s">&quot;VIntWritable&quot;</span><span class="o">,</span> <span class="s">&quot;1,000,000,000&quot;</span><span class="o">,</span><span class="n">hex</span><span class="o">,</span> <span class="n">bs_vint_b</span><span class="o">.</span><span class="na">length</span><span class="o">);</span>
</span><span class="line">
</span><span class="line">		<span class="n">hex</span> <span class="o">=</span> <span class="n">StringUtils</span><span class="o">.</span><span class="na">byteToHexString</span><span class="o">(</span><span class="n">bs_vlong_b</span><span class="o">);</span>
</span><span class="line">		<span class="n">formatPrint</span><span class="o">(</span><span class="s">&quot;VLongWritable&quot;</span><span class="o">,</span> <span class="s">&quot;1,000,000,000&quot;</span><span class="o">,</span> <span class="n">hex</span><span class="o">,</span> <span class="n">bs_vlong_b</span><span class="o">.</span><span class="na">length</span><span class="o">);</span>
</span><span class="line">		
</span><span class="line">		
</span><span class="line">	<span class="o">}</span>
</span><span class="line">
</span><span class="line">	<span class="kd">private</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">formatPrint</span><span class="o">(</span><span class="n">String</span> <span class="n">type</span><span class="o">,</span> <span class="n">String</span> <span class="n">param</span><span class="o">,</span> <span class="n">String</span> <span class="n">hex</span><span class="o">,</span> <span class="kt">int</span> <span class="n">length</span><span class="o">)</span> <span class="o">{</span>
</span><span class="line">
</span><span class="line">		<span class="n">String</span> <span class="n">format</span> <span class="o">=</span> <span class="s">&quot;%1$-50s %2$-16s with length: %3$2d%n&quot;</span><span class="o">;</span>
</span><span class="line">		<span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="n">format</span><span class="o">,</span> <span class="s">&quot;Byte array per &quot;</span> <span class="o">+</span> <span class="n">type</span>
</span><span class="line">				<span class="o">+</span> <span class="s">&quot;(&quot;</span><span class="o">+</span> <span class="n">param</span> <span class="o">+</span><span class="s">&quot;) is:&quot;</span><span class="o">,</span> <span class="n">hex</span><span class="o">,</span> <span class="n">length</span><span class="o">);</span>
</span><span class="line">
</span><span class="line">	<span class="o">}</span>
</span><span class="line">
</span><span class="line">	<span class="cm">/**</span>
</span><span class="line"><span class="cm">	 * Utility method to serialize Writable object, return byte array</span>
</span><span class="line"><span class="cm">	 * representing the Writable object</span>
</span><span class="line"><span class="cm">	 * </span>
</span><span class="line"><span class="cm">	 * */</span>
</span><span class="line">	<span class="kd">public</span> <span class="kd">static</span> <span class="kt">byte</span><span class="o">[]</span> <span class="nf">serialize</span><span class="o">(</span><span class="n">Writable</span> <span class="n">writable</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
</span><span class="line">
</span><span class="line">		<span class="n">ByteArrayOutputStream</span> <span class="n">out</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ByteArrayOutputStream</span><span class="o">();</span>
</span><span class="line">		<span class="n">DataOutputStream</span> <span class="n">dataOut</span> <span class="o">=</span> <span class="k">new</span> <span class="n">DataOutputStream</span><span class="o">(</span><span class="n">out</span><span class="o">);</span>
</span><span class="line">		<span class="n">writable</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="n">dataOut</span><span class="o">);</span>
</span><span class="line">		<span class="n">dataOut</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
</span><span class="line">
</span><span class="line">		<span class="k">return</span> <span class="n">out</span><span class="o">.</span><span class="na">toByteArray</span><span class="o">();</span>
</span><span class="line">
</span><span class="line">	<span class="o">}</span>
</span><span class="line">
</span><span class="line">	<span class="cm">/**</span>
</span><span class="line"><span class="cm">	 * Utility method to deserialize input byte array, return Writable object</span>
</span><span class="line"><span class="cm">	 * </span>
</span><span class="line"><span class="cm">	 * */</span>
</span><span class="line">	<span class="kd">public</span> <span class="kd">static</span> <span class="n">Writable</span> <span class="nf">deserialize</span><span class="o">(</span><span class="n">Writable</span> <span class="n">writable</span><span class="o">,</span> <span class="kt">byte</span><span class="o">[]</span> <span class="n">bytes</span><span class="o">)</span>
</span><span class="line">			<span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
</span><span class="line">
</span><span class="line">		<span class="n">ByteArrayInputStream</span> <span class="n">in</span> <span class="o">=</span> <span class="k">new</span> <span class="n">ByteArrayInputStream</span><span class="o">(</span><span class="n">bytes</span><span class="o">);</span>
</span><span class="line">		<span class="n">DataInputStream</span> <span class="n">dataIn</span> <span class="o">=</span> <span class="k">new</span> <span class="n">DataInputStream</span><span class="o">(</span><span class="n">in</span><span class="o">);</span>
</span><span class="line">		<span class="n">writable</span><span class="o">.</span><span class="na">readFields</span><span class="o">(</span><span class="n">dataIn</span><span class="o">);</span>
</span><span class="line">
</span><span class="line">		<span class="n">dataIn</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
</span><span class="line">		<span class="k">return</span> <span class="n">writable</span><span class="o">;</span>
</span><span class="line">
</span><span class="line">	<span class="o">}</span>
</span><span class="line"><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>程序输出：</p>

<pre><code>Byte array per IntWritable(1,000,000,000) is:  \     
3b9aca00         with length:  4

Byte array per LongWritable(1,000,000,000) is: \     
000000003b9aca00 with length:  8

Byte array per VIntWritable(1,000,000,000) is: \     
8c3b9aca00       with length:  5

Byte array per VLongWritable(1,000,000,000) is:\    
8c3b9aca00       with length:  5
</code></pre>

<p>从上面的输出我们可以看出：</p>

<p>+ 对1,000,000,000的表示不同的Writable占用了不同字节长度</p>

<p>+ 变长Writable类型并不总是比定长类型更加节省空间，当IntWritable占用4个字节、LongWritable占用8个字节时，相应的变长Writable需要一个额外的字节来存放正负信息和字节长度。所以回到前面的整数类型选择的问题上，<strong>选择出最合适的整数Writable类型，我们应该对数值的总体分布有一定的认识</strong>。</p>

<h4 id="text">Text的字节序列</h4>

<p>可以简单的认为Text类是java.lang.String的Writable类型，但是要注意的是Text类对于Unicode字符采用的是UTF-8编码，而不是使用Java Character类的UTF-16编码。</p>

<p>Java Character类采用遵循Unicode Standard version 4的UTF-16编码<a href="http://docs.oracle.com/javase/6/docs/api/java/lang/Character.html">[1]</a>，每个字符采用定长的16位(两个字节)进行编码，对于代码点高于Basic Multilingual Plane(BMP，代码点U+0000～U+FFFF)的增补字符，采用两个代理字符进行表示。</p>

<p>Text类采用的UTF-8编码，使用变长的1～4个字节对字符进行编码。对于ASCII字符只使用1个字节，而对于High ASCII和多字节字符使用2～4个字节表示，我想Hadoop在设计时选择使用UTF-8而不是String的UTF-16就是基于上面的原因，为了节省字节长度/空间的考虑。</p>

<blockquote>
  <p>由于Text采用的是UTF-8编码，所以Text类没有提供String那样多的操作，并且在操作Text对象时，比如Indexing和Iteration，一定要注意这个区别，不过我们建议在进行Text操作时，如果可能可以将Text对象先转换成String，再进行操作。</p>
</blockquote>

<p>Text类的字节序列表示为一个VIntWritable + UTF-8字节流，VIntWritable为整个Text的字符长度，UTF-8字节数组为真正的Text字节流。具体请看下面的代码片段：</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
</pre></td><td class="code"><pre><code class="java"><span class="line"><span class="o">...</span><span class="c1">//omitted per conciseness</span>
</span><span class="line"><span class="n">Text</span> <span class="n">myText</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Text</span><span class="o">(</span><span class="s">&quot;my text&quot;</span><span class="o">);</span>
</span><span class="line"><span class="kt">byte</span><span class="o">[]</span> <span class="n">text_bs</span> <span class="o">=</span> <span class="n">serialize</span><span class="o">(</span><span class="n">myText</span><span class="o">);</span>
</span><span class="line"><span class="n">hex</span> <span class="o">=</span> <span class="n">StringUtils</span><span class="o">.</span><span class="na">byteToHexString</span><span class="o">(</span><span class="n">text_bs</span><span class="o">);</span>
</span><span class="line"><span class="n">formatPrint</span><span class="o">(</span><span class="s">&quot;Text&quot;</span><span class="o">,</span> <span class="s">&quot;\&quot;my text\&quot;&quot;</span><span class="o">,</span> <span class="n">hex</span><span class="o">,</span> <span class="n">text_bs</span><span class="o">.</span><span class="na">length</span><span class="o">);</span>
</span><span class="line">		
</span><span class="line"><span class="n">Text</span> <span class="n">myText2</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Text</span><span class="o">(</span><span class="s">&quot;我的文本&quot;</span><span class="o">);</span>
</span><span class="line"><span class="kt">byte</span><span class="o">[]</span> <span class="n">text2_bs</span> <span class="o">=</span> <span class="n">serialize</span><span class="o">(</span><span class="n">myText2</span><span class="o">);</span>
</span><span class="line"><span class="n">hex</span> <span class="o">=</span> <span class="n">StringUtils</span><span class="o">.</span><span class="na">byteToHexString</span><span class="o">(</span><span class="n">text2_bs</span><span class="o">);</span>
</span><span class="line"><span class="n">formatPrint</span><span class="o">(</span><span class="s">&quot;Text&quot;</span><span class="o">,</span> <span class="s">&quot;\&quot;我的文本\&quot;&quot;</span><span class="o">,</span> <span class="n">hex</span><span class="o">,</span> <span class="n">text2_bs</span><span class="o">.</span><span class="na">length</span><span class="o">);</span>
</span><span class="line"><span class="o">...</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>程序输出：</p>

<pre><code>Byte array per Text("my text") is: \
 	076d792074657874 with length:  8

Byte array per Text("我的文本") is: \
0ce68891e79a84e69687e69cac with length: 13
</code></pre>

<p>在上面的输出中，首个字节代表的该段Text/文本的长度，在UTF-8编码下“my text”占用的字节长度为7个字节（07），而中文“我的文本”的字节长度是12个字节（0c）。</p>

<h4 id="writable-3">定制Writable类的字节序列</h4>

<p>本节中我们将使用上篇文章中的MyWritable类进行说明，回顾一下，MyWritable是一个由两个VLongWritable类构成的定制化Writable类型。</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="java"><span class="line"><span class="o">...</span><span class="c1">//omitted per conciseness</span>
</span><span class="line"><span class="n">MyWritable</span> <span class="n">customized</span> <span class="o">=</span> <span class="k">new</span> <span class="n">MyWritable</span><span class="o">(</span><span class="k">new</span> <span class="n">VLongWritable</span><span class="o">(</span><span class="mi">1000</span><span class="o">),</span>
</span><span class="line"> 						<span class="k">new</span> <span class="nf">VLongWritable</span><span class="o">(</span><span class="mi">1000000000</span><span class="o">));</span>
</span><span class="line"><span class="kt">byte</span><span class="o">[]</span> <span class="n">customized_bs</span> <span class="o">=</span> <span class="n">serialize</span><span class="o">(</span><span class="n">customized</span><span class="o">);</span>
</span><span class="line"><span class="n">hex</span> <span class="o">=</span> <span class="n">StringUtils</span><span class="o">.</span><span class="na">byteToHexString</span><span class="o">(</span><span class="n">customized_bs</span><span class="o">);</span>
</span><span class="line"><span class="n">formatPrint</span><span class="o">(</span><span class="s">&quot;MyWritable&quot;</span><span class="o">,</span> <span class="s">&quot;1000, 1000000000&quot;</span><span class="o">,</span> <span class="n">hex</span><span class="o">,</span> <span class="n">customized_bs</span><span class="o">.</span><span class="na">length</span><span class="o">);</span>
</span><span class="line"><span class="o">...</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>程序输出：</p>

<pre><code>Byte array per MyWritable(1000, 1000000000) is: \
8e03e88c3b9aca00 with length:  8
</code></pre>

<p>从输出我们可以很清楚的看到，定制的Writable类的字节序列实际上就是基本Writable类型的组合，输出“8e03e88c3b9aca00”的前三个字节是1000的VLongWritable的字节序列，“8c3b9aca00”是1000000000VLongWritable的字节序列，这一点可以从我们编写的MyWritable类的write方法中找到答案：</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
</pre></td><td class="code"><pre><code class="java"><span class="line"><span class="o">...</span><span class="c1">//omitted per conciseness</span>
</span><span class="line"><span class="nd">@Override</span>
</span><span class="line"><span class="kd">public</span> <span class="kt">void</span> <span class="nf">write</span><span class="o">(</span><span class="n">DataOutput</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
</span><span class="line">	<span class="n">field1</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="n">out</span><span class="o">);</span>
</span><span class="line">	<span class="n">field2</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="n">out</span><span class="o">);</span>
</span><span class="line"><span class="o">}</span>
</span><span class="line"><span class="o">...</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="section">总结</h4>

<p>本文通过实例介绍了Hadoop Writable类序列化时占用的字节长度，并分析了Writable类序列化后的字节序列的结构。需要注意的是Text类为了节省空间的目的采用了UTF-8的编码，而不是Java Character的UTF-16编码，自定义的Writable的字节序列与该Writable类的write()方法有关。</p>

<p>最后指出，Writable是Hadoop序列化的核心，理解Hadoop Writable的字节长度和字节序列对于选择合适的Writable对象以及在字节层面操作Writable对象至关重要。</p>

<h4 id="section-1">参考资料</h4>

<p>Tom White, Hadoop: The Definitive Guide, 3rd Edition </p>

<p><a href="/blog/2013/05/09/hadoop-serialization-and-writable-object-1/">Hadoop序列化与Writable接口(一)</a></p>

<p><code>---EOF---</code></p>

<!-- reference-like links -->

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/05/09/hadoop-serialization-and-writable-object-1/">Hadoop序列化与Writable接口(一)</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-05-09T20:49:00+08:00" pubdate data-updated="true">May 9<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/05/09/hadoop-serialization-and-writable-object-1/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h4 id="section">序列化</h4>

<p><strong>序列化</strong>（serialization）是指将结构化的对象转化为字节流，以便在网络上传输或者写入到硬盘进行永久存储；相对的<strong>反序列化</strong>（deserialization）是指将字节流转回到结构化对象的过程。</p>

<p>在分布式系统中进程将对象序列化为字节流，通过网络传输到另一进程，另一进程接收到字节流，通过反序列化转回到结构化对象，以达到进程间通信。在Hadoop中，Mapper，Combiner，Reducer等阶段之间的通信都需要使用序列化与反序列化技术。举例来说，Mapper产生的中间结果（<code>&lt;key: value1, value2...&gt;</code>）需要写入到本地硬盘，这是序列化过程（将结构化对象转化为字节流，并写入硬盘），而Reducer阶段读取Mapper的中间结果的过程则是一个反序列化过程（读取硬盘上存储的字节流文件，并转回为结构化对象），需要注意的是，能够在网络上传输的只能是字节流，Mapper的中间结果在不同主机间洗牌时，对象将经历序列化和反序列化两个过程。</p>

<p>序列化是Hadoop核心的一部分，在Hadoop中，位于org.apache.hadoop.io包中的Writable接口是Hadoop序列化格式的实现。</p>

<h4 id="writable">Writable接口</h4>

<p>Hadoop Writable接口是基于DataInput和DataOutput实现的序列化协议，紧凑（高效使用存储空间），快速（读写数据、序列化与反序列化的开销小）。Hadoop中的键（key）和值（value）必须是实现了Writable接口的对象（键还必须实现WritableComparable，以便进行排序）。</p>

<p>以下是Hadoop（使用的是Hadoop 1.1.2）中Writable接口的声明：</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
</pre></td><td class="code"><pre><code class="java"><span class="line"><span class="kn">package</span> <span class="n">org</span><span class="o">.</span><span class="na">apache</span><span class="o">.</span><span class="na">hadoop</span><span class="o">.</span><span class="na">io</span><span class="o">;</span>
</span><span class="line">
</span><span class="line"><span class="kn">import</span> <span class="nn">java.io.DataOutput</span><span class="o">;</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">java.io.DataInput</span><span class="o">;</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">java.io.IOException</span><span class="o">;</span>
</span><span class="line">
</span><span class="line"><span class="kd">public</span> <span class="kd">interface</span> <span class="nc">Writable</span> <span class="o">{</span>
</span><span class="line">  <span class="cm">/** </span>
</span><span class="line"><span class="cm">   * Serialize the fields of this object to &lt;code&gt;out&lt;/code&gt;.</span>
</span><span class="line"><span class="cm">   * </span>
</span><span class="line"><span class="cm">   * @param out &lt;code&gt;DataOuput&lt;/code&gt; to serialize this object into.</span>
</span><span class="line"><span class="cm">   * @throws IOException</span>
</span><span class="line"><span class="cm">   */</span>
</span><span class="line">  <span class="kt">void</span> <span class="nf">write</span><span class="o">(</span><span class="n">DataOutput</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span><span class="o">;</span>
</span><span class="line">
</span><span class="line">  <span class="cm">/** </span>
</span><span class="line"><span class="cm">   * Deserialize the fields of this object from &lt;code&gt;in&lt;/code&gt;.  </span>
</span><span class="line"><span class="cm">   * </span>
</span><span class="line"><span class="cm">   * &lt;p&gt;For efficiency, implementations should attempt to re-use storage in the </span>
</span><span class="line"><span class="cm">   * existing object where possible.&lt;/p&gt;</span>
</span><span class="line"><span class="cm">   * </span>
</span><span class="line"><span class="cm">   * @param in &lt;code&gt;DataInput&lt;/code&gt; to deseriablize this object from.</span>
</span><span class="line"><span class="cm">   * @throws IOException</span>
</span><span class="line"><span class="cm">   */</span>
</span><span class="line">  <span class="kt">void</span> <span class="nf">readFields</span><span class="o">(</span><span class="n">DataInput</span> <span class="n">in</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span><span class="o">;</span>
</span><span class="line"><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="writable-1">Writable类</h4>

<p>Hadoop自身提供了多种具体的Writable类，包含了常见的Java基本类型（boolean、byte、short、int、float、long和double等）和集合类型（BytesWritable、ArrayWritable和MapWritable等）。这些类型都位于org.apache.hadoop.io包中。</p>

<p><img src="http://my.safaribooksonline.com/getfile?item=NDljc3NhNzlyOS9hNWRtNzY4dC8vcGlnMTUwczJlcnl0b3JldW9zcmNhb2VwZWNpaHRvL3R0c2xsbW1vcGkwbGdhZ2Uwbjh5aWwwbWUuMzNz" alt="writable-classes" /></p>

<p>(图片来源：safaribooksonline.com)</p>

<h4 id="writable-2">定制Writable类</h4>

<p>虽然Hadoop内建了多种Writable类提供用户选择，Hadoop对Java基本类型的包装Writable类实现的RawComparable接口，使得这些对象不需要反序列化过程，便可以在字节流层面进行排序，从而大大缩短了比较的时间开销，但是当我们需要更加复杂的对象时，Hadoop的内建Writable类就不能满足我们的需求了(需要注意的是Hadoop提供的Writable集合类型并没有实现RawComparable接口，因此也不满足我们的需要)，这时我们就需要定制自己的Writable类，特别将其作为键（key）的时候更应该如此，以求达到更高效的存储和快速的比较。</p>

<p>下面的实例展示了如何定制一个Writable类，一个定制的Writable类首先必须实现Writable或者WritableComparable接口，然后为定制的Writable类编写write(DataOutput out)和readFields(DataInput in)方法，来控制定制的Writable类如何转化为字节流（write方法）和如何从字节流转回为Writable对象。</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
<span class="line-number">39</span>
<span class="line-number">40</span>
<span class="line-number">41</span>
<span class="line-number">42</span>
<span class="line-number">43</span>
<span class="line-number">44</span>
<span class="line-number">45</span>
<span class="line-number">46</span>
<span class="line-number">47</span>
<span class="line-number">48</span>
<span class="line-number">49</span>
<span class="line-number">50</span>
<span class="line-number">51</span>
<span class="line-number">52</span>
<span class="line-number">53</span>
<span class="line-number">54</span>
<span class="line-number">55</span>
<span class="line-number">56</span>
<span class="line-number">57</span>
<span class="line-number">58</span>
<span class="line-number">59</span>
<span class="line-number">60</span>
<span class="line-number">61</span>
<span class="line-number">62</span>
<span class="line-number">63</span>
<span class="line-number">64</span>
<span class="line-number">65</span>
<span class="line-number">66</span>
<span class="line-number">67</span>
<span class="line-number">68</span>
<span class="line-number">69</span>
<span class="line-number">70</span>
<span class="line-number">71</span>
<span class="line-number">72</span>
<span class="line-number">73</span>
<span class="line-number">74</span>
<span class="line-number">75</span>
<span class="line-number">76</span>
<span class="line-number">77</span>
<span class="line-number">78</span>
<span class="line-number">79</span>
</pre></td><td class="code"><pre><code class="java"><span class="line"><span class="kn">package</span> <span class="n">com</span><span class="o">.</span><span class="na">yoyzhou</span><span class="o">.</span><span class="na">weibo</span><span class="o">;</span>
</span><span class="line">
</span><span class="line"><span class="kn">import</span> <span class="nn">java.io.DataInput</span><span class="o">;</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">java.io.DataOutput</span><span class="o">;</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">java.io.IOException</span><span class="o">;</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">org.apache.hadoop.io.VLongWritable</span><span class="o">;</span>
</span><span class="line"><span class="kn">import</span> <span class="nn">org.apache.hadoop.io.Writable</span><span class="o">;</span>
</span><span class="line">
</span><span class="line"><span class="cm">/**</span>
</span><span class="line"><span class="cm"> *This MyWritable class demonstrates how to write a custom Writable class </span>
</span><span class="line"><span class="cm"> *</span>
</span><span class="line"><span class="cm"> **/</span>
</span><span class="line"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">MyWritable</span> <span class="kd">implements</span> <span class="n">Writable</span><span class="o">{</span>
</span><span class="line">		
</span><span class="line">		
</span><span class="line">	<span class="kd">private</span> <span class="n">VLongWritable</span> <span class="n">field1</span><span class="o">;</span>
</span><span class="line">	<span class="kd">private</span> <span class="n">VLongWritable</span> <span class="n">field2</span><span class="o">;</span>
</span><span class="line">		
</span><span class="line">	<span class="kd">public</span> <span class="nf">MyWritable</span><span class="o">(){</span>
</span><span class="line">		<span class="k">this</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="k">new</span> <span class="n">VLongWritable</span><span class="o">(),</span> <span class="k">new</span> <span class="n">VLongWritable</span><span class="o">());</span>
</span><span class="line">	<span class="o">}</span>
</span><span class="line">		
</span><span class="line">		
</span><span class="line">	<span class="kd">public</span> <span class="nf">MyWritable</span><span class="o">(</span><span class="n">VLongWritable</span> <span class="n">fld1</span><span class="o">,</span> <span class="n">VLongWritable</span> <span class="n">fld2</span><span class="o">){</span>
</span><span class="line">			
</span><span class="line">		<span class="k">this</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">fld1</span><span class="o">,</span> <span class="n">fld2</span><span class="o">);</span>
</span><span class="line">			
</span><span class="line">	<span class="o">}</span>
</span><span class="line">		
</span><span class="line">	<span class="kd">public</span> <span class="kt">void</span> <span class="nf">set</span><span class="o">(</span><span class="n">VLongWritable</span> <span class="n">fld1</span><span class="o">,</span> <span class="n">VLongWritable</span> <span class="n">fld2</span><span class="o">){</span>
</span><span class="line">		<span class="c1">//make sure the smaller field is always put as field1</span>
</span><span class="line">		<span class="k">if</span><span class="o">(</span><span class="n">fld1</span><span class="o">.</span><span class="na">get</span><span class="o">()</span> <span class="o">&lt;=</span> <span class="n">fld2</span><span class="o">.</span><span class="na">get</span><span class="o">()){</span>
</span><span class="line">			<span class="k">this</span><span class="o">.</span><span class="na">field1</span> <span class="o">=</span> <span class="n">fld1</span><span class="o">;</span>
</span><span class="line">			<span class="k">this</span><span class="o">.</span><span class="na">field2</span> <span class="o">=</span> <span class="n">fld2</span><span class="o">;</span>
</span><span class="line">		<span class="o">}</span><span class="k">else</span><span class="o">{</span>
</span><span class="line">				
</span><span class="line">			<span class="k">this</span><span class="o">.</span><span class="na">field1</span> <span class="o">=</span> <span class="n">fld2</span><span class="o">;</span>
</span><span class="line">			<span class="k">this</span><span class="o">.</span><span class="na">field2</span> <span class="o">=</span> <span class="n">fld1</span><span class="o">;</span>
</span><span class="line">		<span class="o">}</span>
</span><span class="line">		<span class="o">}</span>
</span><span class="line">				
</span><span class="line">	<span class="c1">//How to write and read MyWritable fields from DataOutput and DataInput stream</span>
</span><span class="line">	<span class="nd">@Override</span>
</span><span class="line">	<span class="kd">public</span> <span class="kt">void</span> <span class="nf">write</span><span class="o">(</span><span class="n">DataOutput</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
</span><span class="line">			
</span><span class="line">		<span class="n">field1</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="n">out</span><span class="o">);</span>
</span><span class="line">		<span class="n">field2</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="n">out</span><span class="o">);</span>
</span><span class="line">	<span class="o">}</span>
</span><span class="line">
</span><span class="line">	<span class="nd">@Override</span>
</span><span class="line">	<span class="kd">public</span> <span class="kt">void</span> <span class="nf">readFields</span><span class="o">(</span><span class="n">DataInput</span> <span class="n">in</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
</span><span class="line">			
</span><span class="line">		<span class="n">field1</span><span class="o">.</span><span class="na">readFields</span><span class="o">(</span><span class="n">in</span><span class="o">);</span>
</span><span class="line">		<span class="n">field2</span><span class="o">.</span><span class="na">readFields</span><span class="o">(</span><span class="n">in</span><span class="o">);</span>
</span><span class="line">	<span class="o">}</span>
</span><span class="line">
</span><span class="line">	<span class="cm">/** Returns true if &lt;code&gt;o&lt;/code&gt; is a MyWritable with the same values. */</span>
</span><span class="line">	<span class="nd">@Override</span>
</span><span class="line">	<span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">equals</span><span class="o">(</span><span class="n">Object</span> <span class="n">o</span><span class="o">)</span> <span class="o">{</span>
</span><span class="line">		 <span class="k">if</span> <span class="o">(!(</span><span class="n">o</span> <span class="k">instanceof</span> <span class="n">MyWritable</span><span class="o">))</span>
</span><span class="line">		    <span class="k">return</span> <span class="kc">false</span><span class="o">;</span>
</span><span class="line">		
</span><span class="line">		    <span class="n">MyWritable</span> <span class="n">other</span> <span class="o">=</span> <span class="o">(</span><span class="n">MyWritable</span><span class="o">)</span><span class="n">o</span><span class="o">;</span>
</span><span class="line">		    <span class="k">return</span> <span class="n">field1</span><span class="o">.</span><span class="na">equals</span><span class="o">(</span><span class="n">other</span><span class="o">.</span><span class="na">field1</span><span class="o">)</span> <span class="o">&amp;&amp;</span> <span class="n">field2</span><span class="o">.</span><span class="na">equals</span><span class="o">(</span><span class="n">other</span><span class="o">.</span><span class="na">field2</span><span class="o">);</span>
</span><span class="line">		
</span><span class="line">	<span class="o">}</span>
</span><span class="line">		
</span><span class="line">	<span class="nd">@Override</span>
</span><span class="line">	<span class="kd">public</span> <span class="kt">int</span> <span class="nf">hashCode</span><span class="o">(){</span>
</span><span class="line">			
</span><span class="line">		<span class="k">return</span> <span class="n">field1</span><span class="o">.</span><span class="na">hashCode</span><span class="o">()</span> <span class="o">*</span> <span class="mi">163</span> <span class="o">+</span> <span class="n">field2</span><span class="o">.</span><span class="na">hashCode</span><span class="o">();</span>
</span><span class="line">	<span class="o">}</span>
</span><span class="line">		
</span><span class="line">	<span class="nd">@Override</span>
</span><span class="line">	<span class="kd">public</span> <span class="n">String</span> <span class="nf">toString</span><span class="o">()</span> <span class="o">{</span>
</span><span class="line">		<span class="k">return</span> <span class="n">field1</span><span class="o">.</span><span class="na">toString</span><span class="o">()</span> <span class="o">+</span> <span class="s">&quot;\t&quot;</span> <span class="o">+</span> <span class="n">field2</span><span class="o">.</span><span class="na">toString</span><span class="o">();</span>
</span><span class="line">	<span class="o">}</span>
</span><span class="line">		
</span><span class="line"><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>未完待续，下一篇中将介绍Writable对象序列化为字节流时占用的字节长度以及其字节序列的结构。</p>

<h4 id="section-1">参考资料</h4>

<p>Tom White, Hadoop: The Definitive Guide, 3rd Edition </p>

<p><code>---To Be Continued---</code></p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/29/viz-following-networks-of-weibo-celebrities/">微博名人关注网络的社会网络分析</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-29T22:41:00+08:00" pubdate data-updated="true">Apr 29<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/04/29/viz-following-networks-of-weibo-celebrities/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>社交网络分析起源于社会学家使用数学与图论的方法研究社会群组中人与人之间的交互关系，如中心性分析、凝聚子群分析、社会结构分析等，最著名的莫过于美国社会心理学家Stanley Milgram的”六度分离理论”。传统的社会网络分析重点研究的是社会网络分析的概念以及通过社会网络分析研究社会结构对人、组织的影响，但是由于天然的地域限制，网络的大小受到一定的限制。</p>

<p>随着互联网的出现，特别是社交网站的迅速崛起，国外的Facebook、Twitter、Linked，国内的人人、微博等，互联网赋予了社交网络分析前所未有的机遇和新的挑战。首先，互联网打破了地域的限制，无论来自任何地方都可以通过互联网发生联系，目前Facebook有超过10亿的用户，他们来自全球，相互成为好友；其次，获得研究数据变得非常容易，社交网站拥有大量的用户数据，这些数据对社会网络分析来说就是宝贵的财富，以前从未有过，这也是目前社会网络分析在互联网爆发的主要原因；再次，相比于单一的人与人之间的交互关系，社交网站有着丰富的多媒体信息，除了用户关系，还有文本、图片、视频等内容。</p>

<p>但是数据不是信息，面对社交网站上的海量数据，需要有新的方法处理大数据，并从海量数据中挖掘出有价值的信息；同时应用社交网站的用户信息还面临这隐私保护的问题。</p>

<p>本文从社会网络分析的角度分析新浪微博名人帐号的关注网络，通过中介中心性分析关注网络中的控制网络信息流动的中心人物，并且使用<a href="http://en.wikipedia.org/wiki/Modularity_(networks)">Modularity</a>（模块、群组）算法将关注网络划分为不同群组，最后我们使用Gephi可视化微博名人的关注网络。</p>

<h3 id="section">相关理论简介</h3>

<h4 id="section-1">中介中心性</h4>

<p>中介中心性（Betweenness Centrality）是处于网络中的点的中心性/重要程度的一种度量方式，网络中点的中介中心性直观的定义为“该点处于其他点最短路径上的次数”，处于这样位置上的点对路径上的信息传输具有一定的控制（阻止、掩饰、歪曲）能力。因此在同一个网络中，哪一个点的中介中心性越高，该点在网络中对信息的控制能力就越强，相反，中介中心性低，对信息的控制也就低。</p>

<p>如果希望了解中介中心性的详细内容，可参考Wikipedia上的词条<a href="http://en.wikipedia.org/wiki/Betweenness_centrality">Betweenness Centrality</a>，和我的的上两篇文章<a href="/blog/2013/04/28/studying-notes-a-set-of-measures-of-centrality-based-on-betweenness/">A Set of Measures of Centrality Based on Betweenness</a>与<a href="http://yoyzhou.github.io/blog/2013/04/29/a-kinda-betweenness-centrality-algorithm/">A Kinda Betweenness Centrality Algorithm</a>。</p>

<h4 id="section-2">网络群组</h4>

<p>网络群组（Modularity）是社会网络分析中用于分析网络结构的一种方法。根据一个群组内部比群组外部具有更高密度的联结的原则，它将网络分成不同的群组（通常也叫群（groups）、族群（clusters）或者社群（communities）），通常用来侦测网络的社群结构。</p>

<p>更多群组的信息请参考Wikipedia词条<a href="http://en.wikipedia.org/wiki/Modularity_(networks)">Modularity</a>.</p>

<h3 id="section-3">数据来源</h3>

<h4 id="section-4">数据收集</h4>

<p>本文所使用的数据来源于新浪微博的用户关注信息，一共收集了30999个新浪微博用户的关注信息，去重后被关注的用户数量为3,940,891位。</p>

<p>以下是收集数据的概述：</p>

<p><strong>数据收集时间</strong>：2013.3.18~2013.4.2</p>

<p><strong>原始数据</strong>：包含两部分，一部分是用户信息，另一部分是用户的关注信息</p>

<p><strong>用户信息</strong>：用户信息从用户的/info页面上收集</p>

<p><strong>用户关注信息</strong>：用户关注信息从用户的/follow页面逐页收集</p>

<h4 id="section-5">数据预处理</h4>

<p>首先，我们定义微博名人为：在我们所收集的数据中，被关注的次数大于等于1000；然后利用上小节中收集的数据，使用<a href="http://hadoop.apache.org/">Hadoop</a>将数据处理为：”用户, 关注用户”的形式。对于如何在Hadoop中使用Filter处理数据可以参考我的文章<a href="/blog/2013/04/21/adding-filter-in-hadoop-mapper-class/">Adding Filter in Hadoop Mapper Class</a>；最后我们获得了一个包含218,071个节点，677,268条边的微薄名人（有向）关注网络。</p>

<p>需要注意的是在下面的分析中，由于计算资源的有限，我们在Hadoop获得的结果上，进一步将节点数缩小到100个，相应的边的数量为4820。这一步骤是由限制名人网络中节点入度为178实现的。</p>

<h3 id="section-6">微博名人关注网络分析</h3>

<h4 id="section-7">中介中心性和群组分析</h4>

<p>下表列出了中介中心性Top20的微博名人（数据保留小数点后两位）。可以看出在我们的数据集中老沉（新浪执行副总裁、总编辑陈彤）、薛蛮子（著名天使投资人）和徐小平（真格基金创始人、新东方联合创始人）名列前三，李开复中心性值排在第七，为108.16；有11个账户的中介中心性值超过100，他们在网络中处于最短路径上的次数大于100。</p>

<table>
  <tbody>
    <tr>
      <td>排名</td>
      <td>微博帐号</td>
      <td>中介中心性值</td>
      <td>群组</td>
    </tr>
    <tr>
      <td>1</td>
      <td>老沉</td>
      <td>188.31</td>
      <td>0</td>
    </tr>
    <tr>
      <td>2</td>
      <td>薛蛮子</td>
      <td>156.74</td>
      <td>2</td>
    </tr>
    <tr>
      <td>3</td>
      <td>徐小平</td>
      <td>142.70</td>
      <td>0</td>
    </tr>
    <tr>
      <td>4</td>
      <td>王利芬</td>
      <td>127.67</td>
      <td>0</td>
    </tr>
    <tr>
      <td>5</td>
      <td>正和岛刘东华</td>
      <td>124.40</td>
      <td>0</td>
    </tr>
    <tr>
      <td>6</td>
      <td>封新城</td>
      <td>119.40</td>
      <td>2</td>
    </tr>
    <tr>
      <td>7</td>
      <td>李开复</td>
      <td>108.16</td>
      <td>0</td>
    </tr>
    <tr>
      <td>8</td>
      <td>巴曙松</td>
      <td>104.45</td>
      <td>1</td>
    </tr>
    <tr>
      <td>9</td>
      <td>作业本</td>
      <td>103.95</td>
      <td>2</td>
    </tr>
    <tr>
      <td>10</td>
      <td>刘春</td>
      <td>101.13</td>
      <td>1</td>
    </tr>
    <tr>
      <td>11</td>
      <td>张力奋</td>
      <td>100.36</td>
      <td>1</td>
    </tr>
    <tr>
      <td>12</td>
      <td>王冉</td>
      <td>99.05</td>
      <td>0</td>
    </tr>
    <tr>
      <td>13</td>
      <td>财经网</td>
      <td>97.46</td>
      <td>1</td>
    </tr>
    <tr>
      <td>14</td>
      <td>华尔街日报中文网</td>
      <td>94.45</td>
      <td>0</td>
    </tr>
    <tr>
      <td>15</td>
      <td>李承鹏</td>
      <td>88.33</td>
      <td>2</td>
    </tr>
    <tr>
      <td>16</td>
      <td>王克勤</td>
      <td>84.17</td>
      <td>2</td>
    </tr>
    <tr>
      <td>17</td>
      <td>韩寒</td>
      <td>79.72</td>
      <td>2</td>
    </tr>
    <tr>
      <td>18</td>
      <td>章立凡</td>
      <td>76.93</td>
      <td>2</td>
    </tr>
    <tr>
      <td>19</td>
      <td>南都周刊</td>
      <td>75.87</td>
      <td>0</td>
    </tr>
    <tr>
      <td>20</td>
      <td>钱钢</td>
      <td>75.75</td>
      <td>2</td>
    </tr>
  </tbody>
</table>

<p>上表中“群组”列给出了中心性Top20微博名人的群组分类，将他们大致分为三个群组：</p>

<blockquote>
  <p>+ <strong>互联网+青年导师</strong>，</p>
</blockquote>

<blockquote>
  <p>+ <strong>新闻媒体相关</strong>，和</p>
</blockquote>

<blockquote>
  <p>+ <strong>新知识分子</strong>。</p>
</blockquote>

<p>更直观的分类请参看下小节的可视化分析。</p>

<h4 id="section-8">可视化分析</h4>

<p>我们使用<a href="https://gephi.org/">Gephi</a>对微博名人关注网络数据进行可视化分析。如下图所示：</p>

<p>图中节点大小代表中介中心性的大小，节点的颜色代表相应的群组，相同的节点颜色表示处于同一个群组，从图中可以清楚的看到群组的分布情况。</p>

<p><img src="/images/fntk100.png" alt="fntk_100" /></p>

<p><strong>动态交互网络</strong>：</p>

<p><a href="/network/index.html">动态交互网络/Interactive Dynamic Network</a></p>

<h3 id="section-9">结束语</h3>

<p>本文运用社会网络分析方法，通过中介中心性和群组两个维度，对微博名人的关注网络进行了分析，通过分析我们得出了微博名人中介中心性，并且将微博名人的关注网络划分为了三个群组。</p>

<p>虽然本文作者设想将本文作为<code>大数据</code>来进行分析，但是由于计算资源的有限，只能将分析的节点数一再降低；本文中对名人界定以数据集中被关注数量进行度量，更加准确的度量应该以现实微博中用户的被关注数量。</p>

<p>如何在MapReduce框架下进行社交网络分析，将会是一个很价值的主题。</p>

<p>最后，由于本文使用的数据是SINA微博用户数据的很小一部分，文中的排名和可视化网络并非SINA微博真实情况的反映，结论仅供参考。</p>

<p><code>---EOF---</code></p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/29/a-kinda-betweenness-centrality-algorithm/">A Kinda Betweenness Centrality Algorithm</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-29T15:06:00+08:00" pubdate data-updated="true">Apr 29<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/04/29/a-kinda-betweenness-centrality-algorithm/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>In this post I’d like to demonstrate a algorithm per computing the betweenness centrality which I have introduced in the previous post, for more details of what is Betweenness Centrality, and its measurements, please refer to my post <a href="/blog/2013/04/28/studying-notes-a-set-of-measures-of-centrality-based-on-betweenness/">A Set of Measures of Centrality Based on Betweenness</a>. </p>

<h4 id="definitions-and-notations">Definitions and notations</h4>

<p>Before getting down to the algorithm, first we briefly go through the definitions and notations.</p>

<p><strong><em>Betweenness Centrality</em></strong> is “the degree to which a point falls on the shortest path between others”, it’s the core of the algorithm. Although computing <a href="http://en.wikipedia.org/wiki/Shortest_path_problem">shortest path</a> between point pair is essential to our problem, shortest path algorithm will not be the focus of this post. Readers interested in shortest path algorithm please refer to the shortest path on Wikipedia page <a href="http://en.wikipedia.org/wiki/Shortest_path_problem">here</a>, kindly note that even if you have no knowledge of shortest path algorithm, it will not affect you reading this post.</p>

<p>In the next section, we use graph-theoretic terminology neutral to interpretation of notations.</p>

<p>Given a <em>directed graph</em> <script type="math/tex">\begin{smallmatrix} G = \left( V, E \right) \end{smallmatrix}</script>, consists of a set of $V$ of vertices and a set of $E \subseteq V \times V$ of <em>derected</em> edges.</p>

<p>Denote $\sigma(s, t)$ to the number of <em>shortest</em> $(s, t)$-paths, some times called geodesics, and let <script type="math/tex">\sigma(s,t \vert v)</script> be the number of shortest path which passing through certain vertex $v$ other than $s, t$, then the <em>betweenness centrality</em> $C_B(v)$ of vertex $v \in V$ is defined to be:</p>

<script type="math/tex; mode=display">\begin{align}  C_B(v) = \sum\limits_{s,t \in V} \frac{\sigma(s,t \vert v)}{\sigma(s, t)} \end{align}</script>

<h4 id="the-algorithm">The Algorithm</h4>
<p>As quoted from “On variants of shortest-path betweenness centrality and their computation”:</p>

<blockquote>
  <p>Efficient computation of betweenness is based on the fact that the cubic number of <em>pair-wise dependencies <script type="math/tex">\delta(s,t \vert v) = \sigma(s, t \vert v)/ \sigma(s, t)</script></em> can be aggregated without computing all of them explicitly.</p>
</blockquote>

<p>Defining one-side dependencies:</p>

<p><script type="math/tex">\begin{align} \delta(s \vert v) = \sum\limits_{t \in V} \delta(s, t \vert v)\end{align}</script>,</p>

<p>per <script type="math/tex">\forall s, v \in V</script> we can exploit that</p>

<script type="math/tex; mode=display">\begin{align} \delta(s \vert v) = \sum\limits_{w: (v, w) \in E  \ and \\\ dist(s, w) = dist(s, v) + 1} \left[ \frac{\sigma(s,v)}{\sigma(s, w)}
\times \left( 1 + \delta(s \vert w) \right) \right]
\end{align}</script>

<p>where $dist(s, t)$ denotes the minimum path length of point pair $(s, t)$.</p>

<p>The algorithm asserts that the dependency of a vertex $s$ on some $v$ can be compiled from dependencies on vertices <strong><em>one edge farther away</em></strong>. </p>

<p>Since $w$ is connected to $v$ and <strong>one edge farther away</strong> (which determined by <script type="math/tex">dist(s, w) = dist(s, v) + 1</script>) from $v$, so point $v$ is on the shortest paths of $(s, w)$ and the proportion of betweenness value that $v$ gains from edge $(v, w)$ equals to $\frac{\sigma(s,v)}{\sigma(s, w)} \times 1$; the other part of betweenness gain is from point $w$, that <script type="math/tex">\frac{\sigma(s,v)}{\sigma(s, w)} \times \delta(s \vert w)</script>, thus sum of the above two parts of betweenness gain is what exactly the equation demonstrates.</p>

<h4 id="references">References</h4>

<p>[1] Linton C. Freeman. A set of measures of centrality based on betweenness. Sociometry, 40(1):35–41, March 1977.</p>

<p>[2] Ulrik Brandes. On variants of shortest-path betweenness centrality and their generic computation. Social Networks, 30(2):136–145, May 2008.</p>

<p><code>---EOF---</code></p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/28/studying-notes-a-set-of-measures-of-centrality-based-on-betweenness/">A Set of Measures of Centrality Based on Betweenness</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-28T23:49:00+08:00" pubdate data-updated="true">Apr 28<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/04/28/studying-notes-a-set-of-measures-of-centrality-based-on-betweenness/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>This post is a studying notes of paper “A Set of Measures of Centrality Based on Betweenness”, the paper <a href="https://www.tribler.org/trac/raw-attachment/wiki/ReputationFunction/23.pdf">[pdf]</a>, wrote by Freeman in 1977, is an introductory and the most classic paper of <a href="http://en.wikipedia.org/wiki/Betweenness_centrality">betweenness centrality</a>. Based on the betweenness centrality concept first introduced by Bavelas in 1948, the paper introduces a set of measures of centrality, including point centrality, scale free (relative) point centrality, and graph centrality. </p>

<h4 id="betweenness-and-point-centrality">Betweenness and Point Centrality</h4>

<p>The classical centrality measures of Bavelas (1950) etc. can not be used by unconnected networks, since they define the centrality of a point as the sum of the minimum distance between that point and all others, thus all distance sums are infinite in unconnected networks.  </p>

<p>In order to obtain a more satisfactory solution per centrality measurements, Freeman adopts the betweenness concept first introduced by  Bavelas, betweenness of a point is “the degree to which a point falls on the shortest path between others”, and therefore has a potential per control of communication, persons in such central positions could influence the group by “ withholding information (or) coloring, or distorting it in transmission”.</p>

<h4 id="measurement-of-point-centrality">Measurement of Point Centrality</h4>
<p>Consider a unordered pair of  points {<script type="math/tex">p_i, p_j</script>} <script type="math/tex">(i \neq j)</script>. Either <script type="math/tex">p_i \text{ and } p_j</script> are unreachable from each other or  there are one or more paths between them. In the later case, each path has a length equals to the number of edges contained in it. Among the paths connecting pi and pj, one or more have the shortest length: the <strong>geodesics</strong>.</p>

<p>If $p_i$ and $p_j$ are unreachable from each other, then <script type="math/tex">b_{ij}(p_k)</script>, denotes betweenness centrality of point <script type="math/tex">p_k</script> with respect to <script type="math/tex">p_i</script> and <script type="math/tex">p_j</script>, is zero;</p>

<p>If <script type="math/tex">p_i</script> and <script type="math/tex">p_j</script> are <em>adjacent</em>, means that there is only one edge connecting them, since <script type="math/tex">p_k</script> does not reside on the shortest paths of <script type="math/tex">p_i</script> and <script type="math/tex">p_j</script>, <script type="math/tex">b_{ij}(p_k)</script> also equals to zero;</p>

<p>If <script type="math/tex">p_k</script> is on one or more shortest paths of <script type="math/tex">p_i</script> and <script type="math/tex">p_j</script>, in which situations, <script type="math/tex">p_k</script> has a proportional control of communication between <script type="math/tex">p_i</script> and <script type="math/tex">p_j</script>, and intuitively the proportion is the percentage/extent to which <script type="math/tex">p_k</script> is on the shortest paths, given the total shortest paths of <script type="math/tex">p_i</script> and <script type="math/tex">p_j</script> is <script type="math/tex">g_{ij}</script> and the number of <script type="math/tex">p_k</script> falls in the shortest paths is <script type="math/tex">g_{ij}(p_k)</script>, then we get <script type="math/tex">b_{ij}(p_k) = g_{ij}(p_k)/g_{ij}</script>. As the equation shows below:</p>

<script type="math/tex; mode=display">% <![CDATA[
b_{ij}(p_k) = \begin{cases} 
0 & p_i \mbox{ and } p_j \mbox{ are unreachable or adjacent} \\ 
g_{ij}(p_k)/g_{ij} & \text{otherwise} 
\end{cases} %]]></script>

<p>To determine the overall centrality of <script type="math/tex">p_k</script> in the graph, we need merely to sum the partial betweenness value of all unordered pair of points {<script type="math/tex">p_i, p_j</script>} in the graph:</p>

<script type="math/tex; mode=display">\begin{align} C_B(p_k) = \sum\limits_{i}^n \sum\limits_{j}^n b_{ij}(p_k) \mbox{ where } i \lt j \mbox{ and } i,j \neq k  \end{align}</script>

<h4 id="scale-free-point-centrality">Scale-free Point Centrality</h4>

<p>One problem with the above point centrality is it not point independent/scale-free, it is related to how many points in the graph, thus comparing point centrality defined above with different graphs which may contain different amount of point is meaningless. A concreted example is pointed out that  6 betweenness value in 5 points graph compared with 6 betweenness value in 25 points graph, although they have the same betweenness centrality value but the influence of them is different.</p>

<p>In the later section Freeman introduced a relative point centrality, which is scale free to how many points in the graph, where point centrality <script type="math/tex">C'_B(p_k)</script> is divided by the maximum centrality of their graph.</p>

<script type="math/tex; mode=display">\begin{align} C'_B(p_k) = \dfrac{\sum\limits_{i}^n \sum\limits_{j}^n b_{ij}(p_k)} {\mbox{Max } C_B(p_k^*)} \end{align} </script>

<p>where <script type="math/tex">n</script> is the number of points in the graph, and <script type="math/tex">\begin{smallmatrix} \text{Max } C_B(p_k^*) \end{smallmatrix}</script> is only determined by n, which is <script type="math/tex">\begin{smallmatrix} \frac{n \times (n-1)}{2} - (n-1) = \frac{n^2 - 3n + 2}{2} \end{smallmatrix}</script>, therefore we obtain:</p>

<script type="math/tex; mode=display">\begin{align} C'_B(p_k) = \dfrac{2 \times \sum\limits_{i}^n \sum\limits_{j}^n b_{ij}(p_k)}{n^2 - 3n + 2} \end{align} </script>

<p>To get more information of how <script type="math/tex">\begin{smallmatrix} \text{Max } C_B(p_k^*) \end{smallmatrix}</script> is computed, please refer to the paper for details, you can imagine such a point that stands on the shortest path of all other pairs of {<script type="math/tex">p_i, p_j</script>}, where <script type="math/tex">p_i</script> and <script type="math/tex">p_j</script> have merely <strong>one</strong> shortest path, such a graph looks like a star graph, that one point in the central and all others surround it.</p>

<h4 id="graph-centrality">Graph Centrality</h4>

<p>Freeman defines the graph centrality as the average difference between the most central point and all others, which sounds like a little bit of <strong><em>information entropy</em></strong>, I think.</p>

<script type="math/tex; mode=display">\begin{align}
C'_B = \dfrac{\sum\limits_{i}^n \left( C'_B(p_k^*) - C'_B(p_k) \right)}{n - 1} 
\end{align}</script>

<p>where <script type="math/tex">\begin{smallmatrix} C'_B(p_k^*) \end{smallmatrix}</script> is the relative point centrality value of the most central point <script type="math/tex">p_k^*</script> in the graph.</p>

<p>From the equation, we can see if all the points have the same centrality value then the graph centrality is 0; and if the graph is a star or wheel graph, then graph centrality is 1.</p>

<p><code>---EOF---</code></p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/21/adding-filter-in-hadoop-mapper-class/">Adding Filter in Hadoop Mapper Class</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-21T15:08:00+08:00" pubdate data-updated="true">Apr 21<span>st</span>, 2013</time>
        
         | <a href="/blog/2013/04/21/adding-filter-in-hadoop-mapper-class/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>There is my solutions to tackle the disk spaces shortage problem I described in the <a href="/blog/2013/04/20/my-first-luckily-and-sad-hadoop-results/">previous post</a>. The core principle of the solution is to reduce the number of output records at Mapper stage; the method I used is <strong>Filter</strong>, adding a filter, which I will explain later, to decrease the output records of Mapper, which in turn significantly decrease the Mapper’s Spill records, and fundamentally decrease the disk space usages. After applying the filter, with 30,661 records. some 200MB data set as inputs, the total Spill Records is 25,471,725,  and it <strong>only</strong> takes about 509MB disk spaces!</p>

<h4 id="followed-filter">Followed Filter</h4>

<p>And now I’m going to reveal what’s kinda Filter it looks like, and how did I accomplish that filter.
The true face of the <strong>FILTER</strong> is called  <strong>Followed Filter</strong>, it filters users from computing co-followed combinations if their followed number does not satisfy a certain number, called <strong>Followed Threshold</strong>. </p>

<p>Followed Filter is used to reduce the co-followed combinations at Mapper stage. Say we set the followed threshold to 100, meaning users who doesn’t own 100 fans(be followed by 100 other users) will be ignored during co-followed combinations computing stage(to get the actual number of the threshold we need analyze statistics of user’s followed number of our data set).</p>

<h4 id="reason">Reason</h4>

<p>Choosing followed filter is reasonable because how many user follows is a metric of user’s popularity/famousness.</p>

<h4 id="how">HOW</h4>

<p>In order to accomplish it, we need:</p>

<p><strong>First</strong>, counting user’s followed number among our data set, which needs a new MapReduce Job;</p>

<p><strong>Second</strong>, choosing a followed threshold after analyze the statistics perspective of followed number data set got in first step;</p>

<p><strong>Third</strong>, using DistrbutedCache of Hadoop to cache users who satisfy the filter to all Mappers;</p>

<p><strong>Forth</strong>, adding followed filter to Mapper class, only users satisfy filter condition will be passed into co-followed combination computing phrase;</p>

<p><strong>Fifth</strong>, adding co-followed filter/threshold in Reducer side if necessary.</p>

<h4 id="outcomes">Outcomes</h4>
<p>Here is the Hadoop Job Summary, after applying the followed filter with followed threshold of 1000, that means only users who are followed by 1000 users will have the opportunity to co-followed combinations, compared with the Job Summary in my previous post, most all metrics have significant improvements:</p>

<table>
  <tbody>
    <tr>
      <td>Counter</td>
      <td>Map</td>
      <td>Reduce</td>
      <td>Total</td>
    </tr>
    <tr>
      <td>Bytes Written</td>
      <td>0</td>
      <td>1,798,185</td>
      <td>1,798,185</td>
    </tr>
    <tr>
      <td>Bytes Read</td>
      <td>203,401,876</td>
      <td>0</td>
      <td>203,401,876</td>
    </tr>
    <tr>
      <td>FILE_BYTES_READ</td>
      <td>405,219,906</td>
      <td>52,107,486</td>
      <td>457,327,392</td>
    </tr>
    <tr>
      <td><strong><em>HDFS_BYTES_READ</em></strong></td>
      <td><strong><em>203,402,751</em></strong></td>
      <td>0</td>
      <td>203,402,751</td>
    </tr>
    <tr>
      <td><strong><em>FILE_BYTES_WRITTEN</em></strong></td>
      <td>457,707,759</td>
      <td>52,161,704</td>
      <td><strong><em>509,869,463</em></strong></td>
    </tr>
    <tr>
      <td>HDFS_BYTES_WRITTEN</td>
      <td>0</td>
      <td>1,798,185</td>
      <td>1,798,185</td>
    </tr>
    <tr>
      <td>Reduce input groups</td>
      <td>0</td>
      <td>373,680</td>
      <td>373,680</td>
    </tr>
    <tr>
      <td>Map output materialized bytes</td>
      <td>52,107,522</td>
      <td>0</td>
      <td>52,107,522</td>
    </tr>
    <tr>
      <td>Combine output records</td>
      <td>22,202,756</td>
      <td>0</td>
      <td>22,202,756</td>
    </tr>
    <tr>
      <td><strong><em>Map input records</em></strong></td>
      <td><strong><em>30,661</em></strong></td>
      <td>0</td>
      <td>30,661</td>
    </tr>
    <tr>
      <td>Reduce shuffle bytes</td>
      <td>0</td>
      <td>52,107,522</td>
      <td>52,107,522</td>
    </tr>
    <tr>
      <td>Physical memory (bytes) snapshot</td>
      <td>2,646,589,440</td>
      <td>116,408,320</td>
      <td>2,762,997,760</td>
    </tr>
    <tr>
      <td><strong><em>Reduce output records</em></strong></td>
      <td>0</td>
      <td><strong><em>373,680</em></strong></td>
      <td>373,680</td>
    </tr>
    <tr>
      <td><strong><em>Spilled Records</em></strong></td>
      <td><strong><em>22,866,351</em></strong></td>
      <td>2,605,374</td>
      <td>25,471,725</td>
    </tr>
    <tr>
      <td>Map output bytes</td>
      <td>2,115,139,050</td>
      <td>0</td>
      <td>2,115,139,050</td>
    </tr>
    <tr>
      <td>Total committed heap usage (bytes)</td>
      <td>2,813,853,696</td>
      <td>84,738,048</td>
      <td>2,898,591,744</td>
    </tr>
    <tr>
      <td>CPU time spent (ms)</td>
      <td>5,766,680</td>
      <td>11,210</td>
      <td>5,777,890</td>
    </tr>
    <tr>
      <td>Virtual memory (bytes) snapshot</td>
      <td>9,600,737,280</td>
      <td>1,375,002,624</td>
      <td>10,975,739,904</td>
    </tr>
    <tr>
      <td>SPLIT_RAW_BYTES</td>
      <td>875</td>
      <td>0</td>
      <td>875</td>
    </tr>
    <tr>
      <td><strong><em>Map output records</em></strong></td>
      <td><strong><em>117,507,725</em></strong></td>
      <td>0</td>
      <td>117,507,725</td>
    </tr>
    <tr>
      <td>Combine input records</td>
      <td>137,105,107</td>
      <td>0</td>
      <td>137,105,107</td>
    </tr>
    <tr>
      <td>Reduce input records</td>
      <td>0</td>
      <td>2,605,374</td>
      <td>2,605,374</td>
    </tr>
  </tbody>
</table>

<h4 id="ps">P.S.</h4>
<p>Frankly Speaking, chances are <strong>I am on the wrong way to Hadoop Programming</strong>, since I’m palying <code>Pesudo Distribution Hadoop</code> with my personal computer, which has 4 CUPs and 4G RAM, in real Hadoop Cluster disk spaces might never be a trouble, and all the tuning work I have done may turn into meaningless efforts. Before the Followed Filter, I also did some Hadoop tuning like customed Writable class, RawComparator, block size and io.sort.mb, etc.</p>

<p><code>---EOF---</code></p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/20/my-first-luckily-and-sad-hadoop-results/">My First Lucky and Sad Hadoop Results</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-20T17:05:00+08:00" pubdate data-updated="true">Apr 20<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/04/20/my-first-luckily-and-sad-hadoop-results/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Recently I am playing with Hadoop per analyzing the data set I scraped from WEIBO.COM. After a couple of tryings, many are failed due to disk space shortage, after I decreased the input date set volumn, luckily I gained a completed Hadoop Job results, but, sadly, with only 1000 lines of records processed.</p>

<p>Here is the Job Summary:</p>

<table>
  <tbody>
    <tr>
      <td>Counter</td>
      <td>Map</td>
      <td>Reduce</td>
      <td>Total</td>
    </tr>
    <tr>
      <td>Bytes Read</td>
      <td>7,945,196</td>
      <td>0</td>
      <td>7,945,196</td>
    </tr>
    <tr>
      <td>FILE_BYTES_READ</td>
      <td>16,590,565,518</td>
      <td>8,021,579,181</td>
      <td>24,612,144,699</td>
    </tr>
    <tr>
      <td><strong>HDFS_BYTES_READ</strong></td>
      <td><strong><em>7,945,580</em></strong></td>
      <td>0</td>
      <td>7,945,580</td>
    </tr>
    <tr>
      <td>FILE_BYTES_WRITTEN</td>
      <td>24,612,303,774</td>
      <td>8,021,632,091</td>
      <td>32,633,935,865</td>
    </tr>
    <tr>
      <td>HDFS_BYTES_WRITTEN</td>
      <td>0</td>
      <td>2,054,409,494</td>
      <td>2,054,409,494</td>
    </tr>
    <tr>
      <td>Reduce input groups</td>
      <td>0</td>
      <td>381,696,888</td>
      <td>381,696,888</td>
    </tr>
    <tr>
      <td>Map output materialized bytes</td>
      <td>8,021,579,181</td>
      <td>0</td>
      <td>8,021,579,181</td>
    </tr>
    <tr>
      <td>Combine output records</td>
      <td>826,399,600</td>
      <td>0</td>
      <td>826,399,600</td>
    </tr>
    <tr>
      <td><strong>Map input records</strong></td>
      <td><strong><em>1,000</em></strong></td>
      <td>0</td>
      <td>1,000</td>
    </tr>
    <tr>
      <td>Reduce shuffle bytes</td>
      <td>0</td>
      <td>8,021,579,181</td>
      <td>8,021,579,181</td>
    </tr>
    <tr>
      <td>Physical memory (bytes) snapshot</td>
      <td>1,215,041,536</td>
      <td>72,613,888</td>
      <td>1,287,655,424</td>
    </tr>
    <tr>
      <td><strong>Reduce output records</strong></td>
      <td>0</td>
      <td><strong><em>381,696,888</em></strong></td>
      <td>381,696,888</td>
    </tr>
    <tr>
      <td>Spilled Records</td>
      <td>1,230,714,511</td>
      <td>401,113,702</td>
      <td>1,631,828,213</td>
    </tr>
    <tr>
      <td>Map output bytes</td>
      <td>7,667,457,405</td>
      <td>0</td>
      <td>7,667,457,405</td>
    </tr>
    <tr>
      <td>Total committed heap usage (bytes)</td>
      <td>1,038,745,600</td>
      <td>29,097,984</td>
      <td>1,067,843,584</td>
    </tr>
    <tr>
      <td>CPU time spent (ms)</td>
      <td>2,957,800</td>
      <td>2,104,030</td>
      <td>5,061,830</td>
    </tr>
    <tr>
      <td>Virtual memory (bytes) snapshot</td>
      <td>4,112,838,656</td>
      <td>1,380,306,944</td>
      <td>5,493,145,600</td>
    </tr>
    <tr>
      <td>SPLIT_RAW_BYTES</td>
      <td>384</td>
      <td>0</td>
      <td>384</td>
    </tr>
    <tr>
      <td><strong>Map output records</strong></td>
      <td><strong><em>426,010,418</em></strong></td>
      <td>0</td>
      <td>426,010,418</td>
    </tr>
    <tr>
      <td><strong>Combine input records</strong></td>
      <td><strong><em>851,296,316</em></strong></td>
      <td>0</td>
      <td>851,296,316</td>
    </tr>
    <tr>
      <td>Reduce input records</td>
      <td>0</td>
      <td>401,113,702</td>
      <td>401,113,702</td>
    </tr>
  </tbody>
</table>

<p>From which we can see that, specially metrics which highlighted in bold style, I only passed in about 7MB data file with 1000 lines of records, but Reducer outputs 381,696,888 records, which are 2.1GB compressed gz file and some 9GB plain text when decompressed.</p>

<p>But clearly it’s not the problem of my code that leads to so much disk space usages, the above output metrics are all reasonable, although you may be surprised by the comparison between 7MB with only 1000 records input and  9GB  with 381,696,888 records output. The truth is that I’m calculating co-appearance combination computation.</p>

<p>From this experimental I learned that my personal computer really cannot play with big elephant, input data records from the first 10 thousand down to 5 thousand to 3 thousand to ONE thousand at last, but data analytic should go on, I need to find a solution to work it out, actually I have 30 times of data need to process, that is 30 thousand records.</p>

<p>Yet still have a lot of work to do, and I plan to post some articles about what’s I have done with my <em>big data</em> :) and <em>Hadoop</em> so far.</p>

<p><code>---EOF---</code></p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/14/steps-of-programming-hadoop-with-eclipse/">使用Eclipse开发MapReduce程序的步骤</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-14T20:58:00+08:00" pubdate data-updated="true">Apr 14<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/04/14/steps-of-programming-hadoop-with-eclipse/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>以下8个步骤是我在使用Eclipse开发MapReduce程序时的路线，假定读者已经配置好了Hadoop环境并且了解Eclipse的相关操作。</p>

<p>步骤<code>0～4</code>为在Eclipse中编写和调试MapReduce程序；步骤<code>5、6</code>为在伪分布模式下运行MapReduce程序，并且通过导出项目到指定目录实现了Eclipse项目与Hadoop的关联。</p>

<p>0 创建Java项目</p>

<p>1 在项目的CLASS PATH中添加<a href="http://hadoop.apache.org/">Hadoop</a>相关的JAR引用（注意在添加JAR文件，而不是JAR文件夹，要不然在4中会因为找不到JAR或者Class而报错）</p>

<blockquote>
  <p>如果你还下载了Hadoop的<a href="http://hadoop.apache.org/releases.html">源码</a>，也可以给Hadoop相关的JAR添加源码，这样在Eclipse就可以使用F3参看Hadoop源码）</p>
</blockquote>

<p>2 按照<a href="http://hadoop.apache.org/docs/r1.0.4/mapred_tutorial.html">MapReduce</a>类规范，编写自己的MapReduce类</p>

<p>3 配置MapReduce类的运行参数</p>

<p>4 在Eclipse中以单机模式运行/调试程序</p>

<p>5 将程序导出（Export）为JAR文件到$HADOOP_HOME/lib下</p>

<p>6 在伪分布模式下运行程序 bin/hadoop jar lib/ur-exported-jar.JAR full-class-name 参数列表</p>

<blockquote>
  <p>例如，你导出的JAR文件名为myhadoop.jar，类名称com.coolcompany.wordcount，命令就是：bin/hadoop jar lib/myhadoop.jar com.coolcompany.wordcount 参数列表</p>
</blockquote>

<p>7 部署程序到真实的Hadoop集群</p>

<p><code>---EOF---</code></p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/14/hadoop-in-action-reading-note/">Hadoop in Action学习笔记</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-14T15:41:00+08:00" pubdate data-updated="true">Apr 14<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/04/14/hadoop-in-action-reading-note/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><h4 id="hadoop">第一章 Hadoop简介</h4>

<p>现今，互联网每天都产生海量的数据，现有工具对于TB、PB级别大规模分布式海量数据变得无力处理。</p>

<p>Google首先推出了处理大规模分布式数据的MapReduce计算范式，Doug Cutting领导开发了一个开源版的MapReduce，后来成为Hadoop。</p>

<h5 id="hadoop-1">什么是Hadoop</h5>

<p>Hadoop是一个开源框架，可编写和运行分布式应用处理大规模数据。一般认为Hadoop包含两个核心部分：HDFS，Hadoop分布式文件系统和MapReduce，一种分布式编程范式（分布式存储和分布式计算）。</p>

<pre><code>**优点：**
• 方便
• 健壮
• 线性可扩展
• 简单
</code></pre>

<h5 id="vs-">分布式系统  VS 大型单机服务器</h5>

<pre><code>向外扩展 VS  向上扩展

构建在一般/低端商用机器上，廉价

高端服务器，价格昂贵
</code></pre>

<h5 id="hadoopsetihome">Hadoop设计理念和SETI@Home的区别</h5>

<p>Hadoop设计用于数据密集型任务，遵循将程序向数据移动的设计哲学，即尽可能的保持数据不动，减少I/O的访问，程序文件的数量级相对于数据的数量级小得多</p>

<p>SETI@Home设计用于计算密集型任务，遵循将数据向计算资源（计算机）移动的设计哲学；因为数据传输量小，但是需要大量的计算资源（CPU时间）</p>

<h5 id="hadoopsql">Hadoop与SQL数据库的比较</h5>
<p>都是处理数据，SQL数据库用于处理结构化数据</p>

<p>Hadoop应用针对的是文本数据/可能是结构的也可能使非结构或者半结构化数据</p>

<p>1. 向外扩展 代替向上扩展</p>

<p>2. 用键/值对 代替关系表</p>

<p>3. 用函数式编程（MapReduce）代替申明式查询（SQL）</p>

<p>4. 用离线处理代替在线处理</p>

<p>数据密集型分布式应用中，数据传输的代价昂贵，应保持数据存储和处理紧密的绑定在一起。</p>

<h5 id="hadoop-2">Hadoop的历史</h5>
<p>2004年 Goole发表Google文件系统（GFS）和MapReduce框架</p>

<p>Doug Cutting将Nutch项目移植到GFS和MapReduce上，并设立了专门的项目充实这两种技术，于是就有了Hadoop</p>

<p>2006年 Yahoo聘用Doug Cutting，让他和一个专门团队一起改进Hadoop</p>

<p>2008年 Hahoop成为Apache的顶级项目</p>

<h4 id="hadoop-3">第二章 初识Hadoop</h4>

<p><strong>“运行Hadoop”意味着在不同服务器运行一组守护进程（daemons）:</strong></p>

<pre><code>0 NameNode (名字节点)
1 DataNode (数据节点)
2 Secondary NameNode (次名字节点)
3 JobTracker (作业跟踪节点)
4 TaskTracker (任务跟踪节点)
</code></pre>

<p>Hadoop在分布式计算和分布式存储中都采用了<strong>主/从(Master/Slaver)</strong>的结构</p>

<p>NameNode，JobTracker是Master节点</p>

<p>DataNode，TaskTracker和Slaver节点</p>

<h5 id="hadoop-4">运行Hadoop</h5>
<p>配置文件：core-site.xml, hdfs-site.xml和mapred-site.xml</p>

<p>conf/masters - master节点主机列表</p>

<p>conf/slaves - slave节点主机列表</p>

<p>运行的三种模式：本地（单机）模式，伪分布模式和全分布模式</p>

<pre><code>bin/hadoop namenode -format
bin/start-all.sh
jps
</code></pre>

<h5 id="web">基于WEB的管理界面</h5>
<p>NameNode状态界面： namenode-host:50070</p>

<p>JobTracker状态界面： jobtacker-host:50030</p>

<h4 id="hadoop-5">第三章 Hadoop组件</h4>

<p><strong>HDFS文件系统</strong></p>

<p>HDFS是一种文件系统，专为MapReduce这类框架下的大规模分布式处理而设计的</p>

<p>可以处理单个的大数据集（比如100TB），而大多数文件系统物理实现这点。</p>

<p><strong>？</strong>是不是说HDFS处理单个大数据集更加有效，而处理小文件的大量数据变现的不是很有优势，当然，如果这样也可以先把小文件组成大文件。</p>

<p><strong>？</strong>文件要多大才能适合HDFS/Hadoop的处理呢?</p>

<p>可不要为了数据大而大，数据应该在必要的清洗和预处理</p>

<h5 id="hadoop-6">Hadoop的基本文件命令</h5>

<p>hadoop fs -cmd &lt;args&gt;</p>

<p>HDFS中，默认的根目录是/user/$USER 其中USER是你登录系统的用户名</p>

<p>1. 添加文件和目录</p>

<p><code>hadoop fs -mkdir &lt;dir-name&gt;</code></p>

<p>将在/user/$USER目录下创建&lt;dir-name&gt;，如果&lt;dir-name&gt;包含多层目录且上层目录不存在，hadoop fs -mkdir会创建指定的多层目录结构。</p>

<p>如:</p>

<p><code>hadoop fs -mkdir inputs/dataset1 会创建/user/$USER/inputs/dataset1</code></p>

<p>2. 列举文件清单</p>

<p><code>hadoop fs -ls &lt;file-dir-name&gt;</code></p>

<p>和Unix系统ls本地文件类似</p>

<p><code>hadoop fs -lsr &lt;file-dir-name&gt;</code></p>

<p>查看所有文件和文件的子目录，递归的列出文件清单</p>

<p>3. 复制本地文件到HDFS </p>

<p><code>hadoop fs -put &lt;file-dir-name-to-put-in-hdfs&gt; &lt;file-dir-on-hdfs&gt;</code></p>

<p>4. 从HDFS上检索文件到本地系统</p>

<p><code>hadoop fs -get &lt;file-dir-on-hdfs-to-get&gt; &lt;file-dir-name-on-localhost&gt;</code></p>

<p>这是一个与hadoop fs -put相反的操作。</p>

<p>5. 查看HDFS上文件的内容</p>

<p><code>hadoop fs -cat &lt;file-name-to-cat&gt;</code></p>

<p>例如：</p>

<p><code>hadoop fs -cat example.txt</code></p>

<p>同样假设文件在默认的工作目录/user/$USER下</p>

<p>6. 删除文件/目录</p>

<p><code>hadoop fs -rm &lt;file-name-to-remove&gt;</code></p>

<p>例如：</p>

<p><code>hadoop fs -rm example.txt</code></p>

<p>这个命令用来删除文件，要删除文件夹是使用 -rmr 命令：</p>

<p><code>hadoop fs -rmr &lt;dir-name-to-remove&gt;</code></p>

<p>例如：</p>

<p><code>hadoop fs -rmr input</code></p>

<p>这里的<code>r</code>代表递归的删除文件。</p>

<p>7. 查看文件命令帮助</p>

<p><code>hadoop fs -help &lt;cmd&gt;</code></p>

<p>例如：</p>

<p><code>hadoop fs -help rmr</code></p>

<p>查看rmr命令的帮助文件</p>

<p>8. hadoop文件命令与Unix管道一起使用</p>

<p>例如：</p>

<p><code>hadoop fs -cat example.txt | head -n 20</code></p>

<h5 id="hadoop-7">Hadoop数据的读和写</h5>

<p>遵循并行处理数据分片原则的输入数据通常为单一的大文件。这也是Hadoop分布式文件系统的设计策略。</p>

<p>FSDataInputStream支持随机读取，这一特性涉及到MapReduce的数据分片机制。</p>

<p>随机读取，当一个任务失败时，恢复时不用从头读取文件，只需要从失败的位置进行恢复。</p>

<p><strong>InputFormat</strong></p>

<p>Hadoop分割与读取输入文件的方式在InputFormat接口中定义，TextInputFormat是InputFormat的默认实现。Hadoop提供的其他的InputFormat实现有：</p>

<p>KeyValueTextInputFormat，SequenceFileInputFormat和NLineInputFormat</p>

<p><strong>OutputFormat</strong></p>

<p>通过使用IntWritable类变量可以提高reduce()的性能，IntWritable类的处理性能要比Text高。</p>

<h4 id="mapreduce">第四章 编写MapReduce基础程序</h4>

<p><strong>mapper container partitioner reducer</strong> </p>

<h5 id="combiner">使用Combiner提升性能</h5>

<p>Combiner作用上与Reduce等价，起到聚合、结合作用，原则上程序必须没有Combiner也能够得到正确的结果</p>

<p>1. 网络洗牌时减少数据传输流量，考虑10亿条Mapper键值对的输出，如果没有Combiner会在网络洗牌过程中造成多大的流量</p>

<p>2. 数据分布不均匀时，造成大量Mapper的键值对输出跑向同一个Reducer</p>

<p>原理就是通过Combiner减少Mapper的输出数量以降低网络和Reducer上的压力，Combiner位于Mapper和Reducer中间，被视为是Reducer的助手，在数据转换上必须与Reducer等价，也就是如果我们去掉Combiner，Reducer的输出应该保持不变。</p>

<p>但是Combiner未必会提高性能，这要看Combiner是否能有效的减少Mapper输出记录的数量。</p>

<h4 id="mapreduce-1">第五章 高阶MapReduce</h4>

<h5 id="mapreduce-2">MapReduce之间的依赖</h5>

<p>Hadoop通过Job和JobControl类来管理作业之间的非线性依赖关系。</p>

<p>x.addDependingJob(y)</p>

<p>ChainMapper ChainReducer</p>

<p>链接MapReduce是，mapper、reducer之间的输入输出按照值传递还是引用传递的问题。P100</p>

<p>如果确保上游的Map/Reduce不是用其输出数据，或者下游Map/Reduce不改变上游的输出数据，可以使用by reference以提高一定的性能</p>

<h5 id="section">联结不同来源的数据</h5>

<p>1. Reduce侧的联结</p>

<p>repartitioned join 重分区联结</p>

<p>repartitioned sort-mergejoin 重分区排序-合并联结</p>

<p>结合DataJoin包使用钩子处理数据流P93</p>

<p>2. Mapper侧的联结P98</p>

<p><strong>DistributedCache 分布式缓存</strong></p>

<p>应用场景：一个数据源较大，另一个数据源可能小几个数量级，将较小的数据源装入内存，复制到所有的Mapper，在map阶段执行联结。通常小的数据源也叫做“背景数据”</p>

<h4 id="section-1">第六章 编程实践</h4>

<h5 id="section-2">本地模式</h5>

<p><strong>1 计算的完整性检查</strong></p>

<p>数学和逻辑错误在数据密集型程序中更加普遍，而它们往往并不明显！</p>

<p>数学计数或者算术如何检查正确性，在分布式计算中数学公式可能要重新设计，但是如何验证计算的完整性和准确性也就十分的重要。</p>

<p><strong>方法：</strong></p>

<p>可是通过宏观的查看一些指标，比如平均值，整体计数、最大值等来进行初步验证</p>

<p><strong>2 回归测试</strong></p>

<p>可能代价会很大，但是可以选取一部分数据集进行测试。所谓回归测试就是在同一数据集上比较代码修改前后算法的输出结果是否一致，如果每次回归测试的结果都是一样的，那么可以判定修改没有导致出现新的问题。</p>

<p><strong>3 考虑使用LONG而不是INT</strong></p>

<h5 id="section-3">伪分布模式</h5>
<p>1 日志</p>

<p>2 JOBTRACKER的WEB管理界面</p>

<p>3 杀掉作业</p>

<h5 id="section-4">生产集群上的监控与调试</h5>
<p>计数器 Reporter.incrCounter()</p>

<p>跳过坏记录 skipping模式的设置P126</p>

<p>用IsolationRunner重新运行出错的任务</p>

<h5 id="section-5">性能调优</h5>

<p><strong>Hadoop的线性可扩展性</strong></p>

<h6 id="combiner-1">1 通过combiner来减少网络流量</h6>

<h6 id="section-6">2 减少输入数据</h6>
<pre><code>a. 采样数据，只处理数据的子集
b. “重构”数据，仅使用需要的字段（要求开发人员清楚的了解数据和自己的业务需求）
#上面两个方案一个是**横切**一个是**纵切**，都是减少输入数据的方法
</code></pre>

<h6 id="section-7">3 使用压缩</h6>

<p>即使使用了combiner，在map阶段的输出也可能很大。这些中间数据必须被存储在磁盘上，并在网络上重排。压缩这些中间数据会提高大多数MapReduce作业的性能。Hadoop内置支持压缩和解压缩。</p>

<pre><code>压缩的参数配置P130
mapred.compress.map.output
mapred.map.output.compression.codec
SequenceFIleOutputFormat 序列文件输出
</code></pre>

<h6 id="jvm">4 重用JVM</h6>

<p>mapred.job.reuse.jvm.num.task 指定一个JVM可以运行的最大任务数</p>

<h6 id="section-8">5 根据猜测执行来运行</h6>

<p>在所有的mapper完成之前，reducer都不会启动；类似的，在所有的reducer完成之前，一个作业也不会结束。</p>

<p><strong>问题：当其中一个任务变慢时（注意不是失效），MapReduce如何处理？</strong></p>

<p>Hadoop会注意到运行速度缓慢的任务，并安排在另一个节点上并行执行相同的任务。</p>

<pre><code>**参数：**

mapred.map.tasks.speculative.execution
mapred.reduce.tasks.speculative.execution
</code></pre>

<h6 id="section-9">6 代码重构与算法重写</h6>

<p>6.1 将Streaming程序重写为Java程序</p>

<p>6.2 在一次作业中集中一次处理类似的任务，而不是每一个任务都启动一个作业，比如计算最大值、最小值和均值等在同一数据集上的计算可以在一个Job中完成，而不要分为不同的Job</p>

<p>6.3 设计特定的新的适合MapReduce框架的算法</p>

<h4 id="section-10">第七章 细则手册</h4>

<h5 id="section-11">7.1 向任务传递作业定制的参数</h5>

<p>在JobConf中定制自己的参数，在所有的Task中都能读取到。</p>

<h5 id="section-12">7.2 探查任务特定信息</h5>

<h5 id="section-13">7.3 划分为多个输出文件</h5>
<p>MultipleOutputFormat 键/值区分，写入不同的文件， 一个Collector 不同文件名</p>

<p>MultipleOutputs	属性区分，写入不同的文件，多个Collector写文件</p>

<h5 id="section-14">7.4 以数据库作为输入输出</h5>
<p><strong>DBOutputFormat</strong></p>

<h5 id="section-15">7.5 保持输出的顺序</h5>

<h4 id="hadoop-8">第八章 管理Hadoop</h4>

<h5 id="section-16">8.1 为实际应用设置特定参数值</h5>

<h5 id="section-17">8.2 系统体检</h5>
<pre><code>bin/hadoop fsck &lt;path&gt; #file system check
bin/hadoop dfsadmin -report
</code></pre>

<h5 id="section-18">8.3 权限设置</h5>

<h5 id="section-19">8.4 配额管理</h5>
<pre><code>bin/hadoop dfsadmin -setQuota &lt;N&gt; dir
bin/hadoop dfsadmin -setSpaceQuota &lt;N&gt; dir
bin/hadoop fs -count -q dir #显示目录的配额
</code></pre>

<h5 id="section-20">8.5 启动回收站</h5>

<p>fs.trash.interval属性（以分钟为单位）</p>

<h5 id="datanode">8.6 删减DataNode</h5>

<pre><code>dfs.hosts.exclude=file-point-to-exclude-host-list
bin/hadoop dfsadmin -refreshNodes
</code></pre>

<h5 id="datanode-1">8.7 增加DataNode</h5>

<h5 id="namenodesnn">8.8 管理NameNode和SNN</h5>
<p>减轻NameNode负担的一种方法是增加数据块的大小，以降低文件系统中元数据的数据量，dfs.block.size 默认64M</p>

<h6 id="snn">SNN是做什么的？</h6>
<p>取了一个不妥的名字。首先并不是NameNode的失效备份</p>

<p>把SNN视为一个检查点服务器更为合适，用于合并下面两个文件以形成系统快照。</p>

<pre><code>可能在0.21中被弃用
FsImage
EditLog
</code></pre>

<h5 id="namenode">8.9 恢复失效的NameNode</h5>
<p>备份NameNode的元数据文件（dfs.name.dir）到SNN节点，或者其他多个节点。</p>

<h5 id="section-21">8.10 感知网络布局和机架的设计</h5>
<p><strong>DataNode数据块的副本策略</strong>
标准副本为3个：</p>

<p>第1个 在同一个DataNode上</p>

<p>第2个 不同的机架上的DataNode上</p>

<p>第3个 与第二个同机架的不同DataNode上</p>

<p>如果大于3个副本，其他的随机放置的不同节点上</p>

<p>topology.script.file.name</p>

<p>机架感知，配置Hadoop是NameNode知道DataNode的机架分布结构</p>

<h5 id="section-22">8.11 多用户作业调度</h5>
<p>8.11.1 多个JobTracker</p>

<p>8.11.2 公平调度器 （Facebook）</p>

<h4 id="hadoop-9">第九章 在云上运行Hadoop</h4>
<p><strong>租用 经济</strong>
Amazon Web Services(AWS)</p>

<p>Elastic Compute Clous(EC2) 弹性计算云</p>

<p>Simple Storage Service(S3)简单存储服务</p>

<p>1 AWS与外部网络通信的带宽需要收取费用，EC2内部不需要收费。</p>

<p>2 先存储在S3 在从S3中复制到主节点</p>

<p>S3中存储数据同样要收费 但是 存储空间可扩展、一次存储可以多次使用、资费相对低、S3和EC2是内部网，之间复制数据没有费用且速度快</p>

<p>3 还可以直接将S3作为输入输出文件地址，而不用复制数据到HDFS</p>

<h4 id="pignot-finished">第十章 用Pig编程（Not Finished）</h4>
<p>Pig是架构在Hadoop之上的高级数据处理层。</p>

<p><strong>易用性、高性能、大规模可扩展能力</strong>是所有Hadoop子项目的期望</p>

<p><strong>“Pig吃任何东西”</strong></p>

<p>Pig Latin命令运行： Grunt Shell、脚本文件、嵌入在Java程序中。</p>

<h4 id="hivehadoop">第十一章 Hive及Hadoop群</h4>
<p>Pig——一种高级数据流语言</p>

<p>Hive——一种类SQL数据仓库基础设施</p>

<p>HBase——一种模仿Google BigTable的分布式的、面向列的数据库</p>

<p>ZooKeeper——一种用于管理分布式应用之间共享状态的可靠的协同系统</p>

<p>Cascading——是Hadoop上用于组装和执行复杂数据处理工作流的一个API</p>

<p>Hama——矩阵计算软件包，用于计算乘积、逆、特征值、特征向量和其他矩阵运算</p>

<p>Mahout——基于Hadoop实现机器学习算法</p>

<h5 id="hive">Hive</h5>
<p>Hive是建立在Haddop基础之上的数据仓库软件包</p>

<p>HiveQL——类SQL的数据查询语言</p>

<p>MetaStore ——用于存放元数据的组件，存储在Derby关系数据库中（存取速度的考虑）</p>

<p><code>---EOF---</code></p>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2013/04/08/weibo-scrapy-framework-with-multi-threading/">基于UID的WEIBO信息抓取框架WEIBO_SCRAPY</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2013-04-08T20:55:00+08:00" pubdate data-updated="true">Apr 8<span>th</span>, 2013</time>
        
         | <a href="/blog/2013/04/08/weibo-scrapy-framework-with-multi-threading/#disqus_thread">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>本文介绍基于微博UID的SINA微博信息抓取框架WEIBO_SCRAPY。 WEIBO_SCRAPY是一个PYTHON实现的，使用多线程抓取WEIBO信息的框架。WEIBO_SCRAPY框架给用户提供WEIBO的模拟登录和多线程抓取微博信息的接口，让用户只需关心抓取的业务逻辑，而不用处理棘手的WEIBO模拟登录和多线程编程。</p>

<h3 id="weiboscrapy">WEIBO_SCRAPY</h3>
<p>WEIBO_SCRAPY是一个PYTHON实现的，使用基于微博UID的方式从WEIBO.COM页面抓取信息的框架。框架以微博UID为最小单位，为每一个UID分配一个抓取线程，因此每一个UID相当于一个<strong>抓取任务</strong>。WEIBO_SCRAPY内置微博模拟登录和多线程框架，让用户只需关注以微博UID为基础的抓取业务逻辑。具体的说，使用WEIBO_SCRAPY用户只需要重载WEIBO_SCRAPY的<strong>抓取任务</strong>方法为自己的抓取逻辑，即可实现多线程地抓取微博信息（详见下文<code>WEIBO_SCRAPY的实现</code>小节）。</p>

<h3 id="weiboscrapy-1">WEIBO_SCRAPY的功能</h3>
<p>1. 微博模拟登录</p>

<p>2. 多线程抓取框架</p>

<p>3. <strong>抓取任务</strong>接口</p>

<p>4. 抓取参数配置</p>

<h3 id="weiboscrapy-2">WEIBO_SCRAPY的实现</h3>

<h4 id="section">1 微博模拟登录</h4>
<p>请参考拙文<a href="/blog/2013/03/18/sina-weibo-login-simulator-in-python/">Python模拟登录新浪微薄（使用RSA加密方式和Cookies文件）</a></p>

<h4 id="section-1">2 多线程抓取框架</h4>
<p>WEIBO_SCRAPY使用<a href="http://docs.python.org/2/library/queue.html">Queue</a>实现多线程抓取框架，Queue中的元素为微博用户的UID，每一个抓取线程消费Queue中的UID，抓取线程在获得UID之后交给<strong>抓取任务</strong>处理该UID。框架实现<code>从某一个UID开始</code>和<code>从文件中加载UID列表</code>两种抓取方式，无论何种方式都有可能返回在抓取过程中新获得的UID(通过解析抓取的页面获得)，并加入到Queue中，对于从单一某个UID开始的方式，返回新获得的UID是推荐的做法，不然Queue中就只有开始UID一个抓取任务。</p>

<blockquote>
  <p>The Queue module implements multi-producer, multi-consumer queues. It is especially useful in threaded programming when information must be exchanged safely between multiple threads. </p>
</blockquote>

<p>关于更多Python多线程编程的知识，请参考拙文<a href="/blog/2013/02/28/python-threads-synchronization-locks/">Python线程同步机制: Locks, RLocks, Semaphores, Conditions, Events和Queues</a></p>

<p>以下是WEIBO_SCRAPY多线程框架的实现代码，分别是抓取线程和抓取的主进程，在第二段代码中抓取的主进程生成用户指定数目的抓取进行执行抓取任务：</p>

<p>抓取线程</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
<span class="line-number">29</span>
<span class="line-number">30</span>
<span class="line-number">31</span>
<span class="line-number">32</span>
<span class="line-number">33</span>
<span class="line-number">34</span>
<span class="line-number">35</span>
<span class="line-number">36</span>
<span class="line-number">37</span>
<span class="line-number">38</span>
<span class="line-number">39</span>
<span class="line-number">40</span>
<span class="line-number">41</span>
<span class="line-number">42</span>
<span class="line-number">43</span>
<span class="line-number">44</span>
<span class="line-number">45</span>
<span class="line-number">46</span>
<span class="line-number">47</span>
<span class="line-number">48</span>
<span class="line-number">49</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">class</span> <span class="nc">scrapy_threading</span><span class="p">(</span><span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="p">):</span>
</span><span class="line">    <span class="sd">&quot;&quot;&quot;Thread class to handle scrapy task&quot;&quot;&quot;</span>
</span><span class="line">
</span><span class="line">    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">task</span><span class="p">,</span> <span class="n">wanted</span><span class="p">):</span>
</span><span class="line">        <span class="n">threading</span><span class="o">.</span><span class="n">Thread</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">do_task</span> <span class="o">=</span> <span class="n">task</span>
</span><span class="line">        <span class="bp">self</span><span class="o">.</span><span class="n">wanted</span> <span class="o">=</span> <span class="n">wanted</span>
</span><span class="line">
</span><span class="line">    <span class="k">def</span> <span class="nf">run</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class="line">        <span class="k">global</span> <span class="n">visited_uids</span>
</span><span class="line">        <span class="k">global</span> <span class="n">task_queue</span>
</span><span class="line">        <span class="k">global</span> <span class="n">scraped</span>
</span><span class="line">        <span class="k">global</span> <span class="n">lock</span>
</span><span class="line">
</span><span class="line">        <span class="k">while</span> <span class="n">scraped</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">wanted</span><span class="p">:</span>
</span><span class="line">
</span><span class="line">            <span class="c">#crawl info based on each uid</span>
</span><span class="line">            <span class="k">if</span> <span class="n">task_queue</span><span class="p">:</span>
</span><span class="line">
</span><span class="line">                <span class="n">uid</span> <span class="o">=</span> <span class="n">task_queue</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
</span><span class="line">
</span><span class="line">                <span class="k">if</span> <span class="n">uid</span> <span class="ow">in</span> <span class="n">visited_uids</span><span class="p">:</span> <span class="c">#already crawled</span>
</span><span class="line">                    <span class="n">task_queue</span><span class="o">.</span><span class="n">task_done</span><span class="p">()</span>
</span><span class="line">
</span><span class="line">                <span class="k">else</span><span class="p">:</span>
</span><span class="line">                    <span class="k">try</span><span class="p">:</span>
</span><span class="line">                        <span class="n">gains</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_task</span><span class="p">(</span><span class="n">uid</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">                        <span class="c">#per debug</span>
</span><span class="line">                        <span class="n">wow</span> <span class="o">=</span> <span class="s">&#39;{0: &lt;25}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s">&#39;[&#39;</span> <span class="o">+</span> <span class="n">time</span><span class="o">.</span><span class="n">asctime</span><span class="p">()</span> <span class="o">+</span> <span class="s">&#39;] &#39;</span><span class="p">)</span> <span class="o">+</span> <span class="s">&#39; uid_&#39;</span> <span class="o">+</span> <span class="s">&#39;{0: &lt;12}&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">uid</span><span class="p">)</span>
</span><span class="line">                        <span class="k">print</span> <span class="n">wow</span>
</span><span class="line">                        <span class="k">for</span> <span class="n">uid</span> <span class="ow">in</span> <span class="n">gains</span><span class="p">:</span>
</span><span class="line">                            <span class="n">task_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">uid</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">                        <span class="c">#signals that queue job is done</span>
</span><span class="line">                        <span class="n">task_queue</span><span class="o">.</span><span class="n">task_done</span><span class="p">()</span>
</span><span class="line">
</span><span class="line">                        <span class="c">#counting scrapied number</span>
</span><span class="line">                        <span class="k">with</span> <span class="n">lock</span><span class="p">:</span>
</span><span class="line">                            <span class="n">scraped</span> <span class="o">+=</span> <span class="mi">1</span>
</span><span class="line">                            <span class="c">#per debug</span>
</span><span class="line">                            <span class="k">print</span> <span class="s">&#39;scraped: &#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">scraped</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">                    <span class="k">except</span> <span class="ne">Exception</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span>
</span><span class="line">                        <span class="k">print</span> <span class="n">e</span>
</span><span class="line">                        <span class="k">pass</span>
</span><span class="line">
</span><span class="line">            <span class="k">else</span><span class="p">:</span>
</span><span class="line">                <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>抓取的主进程</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="k">def</span> <span class="nf">scrapy</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class="line">
</span><span class="line">        <span class="n">login_status</span> <span class="o">=</span> <span class="n">login</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">login_username</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">login_password</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cookies_file</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">        <span class="k">if</span> <span class="n">login_status</span><span class="p">:</span>
</span><span class="line">
</span><span class="line">            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">start_uid</span><span class="p">:</span>
</span><span class="line">                <span class="n">task_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">start_uid</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">            <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">uids_file</span><span class="p">:</span>
</span><span class="line">                <span class="n">uids_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">__load_uids__</span><span class="p">()</span>
</span><span class="line">                <span class="k">for</span> <span class="n">uid</span> <span class="ow">in</span> <span class="n">uids_list</span><span class="p">:</span>
</span><span class="line">                    <span class="n">task_queue</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="n">uid</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">            <span class="k">else</span><span class="p">:</span> <span class="c">#start uid or uids file is needed</span>
</span><span class="line">                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s">&#39;ERROR: Start uid or uids file is needed.&#39;</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">            <span class="c">#spawn a pool of threads, and pass them queue instance </span>
</span><span class="line">            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">thread_number</span><span class="p">):</span>
</span><span class="line">                <span class="n">st</span> <span class="o">=</span> <span class="n">scrapy_threading</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scrapy_do_task</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">wanted</span><span class="p">)</span>
</span><span class="line">                <span class="n">st</span><span class="o">.</span><span class="n">setDaemon</span><span class="p">(</span><span class="bp">True</span><span class="p">)</span>
</span><span class="line">                <span class="n">st</span><span class="o">.</span><span class="n">start</span><span class="p">()</span>
</span><span class="line">
</span><span class="line">
</span><span class="line">            <span class="n">task_queue</span><span class="o">.</span><span class="n">join</span><span class="p">()</span>
</span><span class="line">
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h4 id="section-2">3 抓取任务接口</h4>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="python"><span class="line">  <span class="k">def</span> <span class="nf">scrapy_do_task</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">uid</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
</span><span class="line">        <span class="sd">&#39;&#39;&#39;</span>
</span><span class="line"><span class="sd">        User needs to overwrite this method to perform uid-based scrapy task.</span>
</span><span class="line"><span class="sd">        @param uid: weibo uid</span>
</span><span class="line"><span class="sd">        @return: a list of uids gained from this task, optional</span>
</span><span class="line"><span class="sd">        &#39;&#39;&#39;</span>
</span><span class="line">        <span class="c">#return []</span>
</span><span class="line">        <span class="k">pass</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>以上是抓取任务的接口，WEIBO_SCRAPY暴露scrapy_do_task方法，用户只需要继承WEIBO_SCRAPY的scrapy类并且重写scrapy_do_task方法为自己的抓取业务逻辑。
像前面提到过的一样，抓取任务是基于微博用户的UID的，所以scrapy_do_task方法有一个uid参数。</p>

<h4 id="section-3">4 抓取参数配置</h4>
<p>WEIBO_SCRAPY提供简单易用的账户信息配置和抓取参数配置，在<code>scrapy.ini</code>文件中即可轻松的完成参数的配置，以下是一个配置文件的样本：</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="p">[</span><span class="n">login_account_info</span><span class="p">]</span>
</span><span class="line"><span class="c">#account info for logining weibo </span>
</span><span class="line"><span class="n">login_username</span> <span class="o">=</span> <span class="n">ur_login_account_name_here</span>
</span><span class="line"><span class="n">login_uid</span> <span class="o">=</span> <span class="n">weibo_uid_of_login_account_here</span>
</span><span class="line"><span class="n">login_password</span> <span class="o">=</span> <span class="n">account_password_here</span>
</span><span class="line"><span class="n">cookies_file</span> <span class="o">=</span> <span class="n">weibo_cookies</span><span class="o">.</span><span class="n">dat</span>
</span><span class="line">
</span><span class="line"><span class="p">[</span><span class="n">scrapy_settings</span><span class="p">]</span>
</span><span class="line"><span class="n">thread_number</span> <span class="o">=</span> <span class="mi">50</span>
</span><span class="line"><span class="n">wanted</span> <span class="o">=</span> <span class="mi">100000</span>
</span><span class="line"><span class="c">#only one property of below 2 is required, and start_uid takes advantage of uids_file</span>
</span><span class="line"><span class="c">#also note that arguments from constructor will overwrite this two properties </span>
</span><span class="line"><span class="n">start_uid</span> <span class="o">=</span> <span class="mi">1197161814</span>
</span><span class="line"><span class="n">uids_file</span> <span class="o">=</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>用户也可以在scrapy类的构造器中指定配置文件的位置。</p>

<h3 id="weiboscrapy-3">WEIBO_SCRAPY的使用</h3>
<p>使用WEIBO_SCRAPY用户只需要继承WEIBO_SCRAPY的scrapy类并且重写scrapy_do_task方法为自己的抓取业务逻辑。</p>

<p>以下示例代码可在<a href="https://github.com/yoyzhou/weibo_scrapy/blob/master/example.py">weibo_scrapy/example.py</a>中找到。</p>

<div class="bogus-wrapper"><notextile><figure class="code"> <div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
</pre></td><td class="code"><pre><code class="python"><span class="line"><span class="c">#!/usr/bin/env python</span>
</span><span class="line"><span class="c">#coding=utf8</span>
</span><span class="line">
</span><span class="line"><span class="kn">from</span> <span class="nn">weibo_scrapy</span> <span class="kn">import</span> <span class="n">scrapy</span>
</span><span class="line">
</span><span class="line">
</span><span class="line"><span class="k">class</span> <span class="nc">my_scrapy</span><span class="p">(</span><span class="n">scrapy</span><span class="p">):</span>
</span><span class="line">
</span><span class="line">    <span class="k">def</span> <span class="nf">scrapy_do_task</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">uid</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
</span><span class="line">         <span class="sd">&#39;&#39;&#39;</span>
</span><span class="line"><span class="sd">        User needs to overwrite this method to perform uid-based scrapy task.</span>
</span><span class="line"><span class="sd">        @param uid: weibo uid</span>
</span><span class="line"><span class="sd">        @return: a list of uids gained from this task, optional</span>
</span><span class="line"><span class="sd">        &#39;&#39;&#39;</span>
</span><span class="line">         <span class="nb">super</span><span class="p">(</span><span class="n">my_scrapy</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwds</span><span class="p">)</span>
</span><span class="line">
</span><span class="line">         <span class="c">#do what you want with uid here, note that this scrapy is uid based, so make sure there are uids in task queue, </span>
</span><span class="line">         <span class="c">#or gain new uids from this function</span>
</span><span class="line">         <span class="k">print</span> <span class="s">&#39;WOW...&#39;</span>
</span><span class="line">         <span class="k">return</span> <span class="s">&#39;replace this string with uid list which gained from this task&#39;</span>
</span><span class="line">
</span><span class="line"><span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">&#39;__main__&#39;</span><span class="p">:</span>
</span><span class="line">
</span><span class="line">    <span class="n">s</span> <span class="o">=</span> <span class="n">my_scrapy</span><span class="p">(</span><span class="n">start_uid</span> <span class="o">=</span> <span class="s">&#39;1197161814&#39;</span><span class="p">)</span>
</span><span class="line">    <span class="n">s</span><span class="o">.</span><span class="n">scrapy</span><span class="p">()</span>
</span><span class="line">
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="section-4">项目源代码</h3>
<p>WEIBO_SCRAPY项目的源代码地址：<a href="https://github.com/yoyzhou/weibo_scrapy">weibo_scrapy</a>，<a href="https://github.com/yoyzhou/weibo_scrapy/fork">Fork it</a>。</p>

<h3 id="section-5">相关阅读</h3>
<p>1. <a href="/blog/2013/03/18/sina-weibo-login-simulator-in-python/">Python模拟登录新浪微薄（使用RSA加密方式和Cookies文件）</a></p>

<p>2. <a href="/blog/2013/03/23/extract-data-with-beautifulsoup-taking-weibo-4-example/">使用Beautiful Soup抽取网页数据，解析微博用户关注信息</a></p>

<p><code>---EOF---</code></p>

<!-- PUT reference-style links below-->

</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <ul id="recent_posts">
      <li class="post">
      <a href="http://yoyzhou.github.com" alt="Home"><img src="/images/Home.png"></a>
      <a href="http://yoyzhou.github.com/archives/" alt="Archives"><img src="/images/Calendar.png"></a>
      <a href="mailto:" alt="E-Mail"><img src="/images/Envelope.png"></a>
      <a href="http://yoyzhou.github.com/atom.xml" alt="subscribe feed"><img src="/images/rss_big.png"></a>
      </li>
  </ul>
</section>
<section>
  <h1>About Me</h1>
 <p><code>[DATA itself is NOTHING, no matter how biiig it is, we NEED <strong>mine</strong> the value out of it.]</code></p>
</section>
<section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2013/05/10/hadoop-serialization-and-writable-object-2/">Hadoop序列化与Writable接口(二)</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/05/09/hadoop-serialization-and-writable-object-1/">Hadoop序列化与Writable接口(一)</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/04/29/viz-following-networks-of-weibo-celebrities/">微博名人关注网络的社会网络分析</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/04/29/a-kinda-betweenness-centrality-algorithm/">A Kinda Betweenness Centrality Algorithm</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/04/28/studying-notes-a-set-of-measures-of-centrality-based-on-betweenness/">A Set of Measures of Centrality Based on Betweenness</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/04/21/adding-filter-in-hadoop-mapper-class/">Adding Filter in Hadoop Mapper Class</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/04/20/my-first-luckily-and-sad-hadoop-results/">My First Lucky and Sad Hadoop Results</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/04/14/steps-of-programming-hadoop-with-eclipse/">使用Eclipse开发MapReduce程序的步骤</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/04/14/hadoop-in-action-reading-note/">Hadoop in Action学习笔记</a>
      </li>
    
      <li class="post">
        <a href="/blog/2013/04/08/weibo-scrapy-framework-with-multi-threading/">基于UID的WEIBO信息抓取框架WEIBO_SCRAPY</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>GitHub Repos</h1>
  <ul id="gh_repos">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  
  <a href="https://github.com/yoyzhou">@yoyzhou</a> on GitHub
  
  <script type="text/javascript">
    $.domReady(function(){
        if (!window.jXHR){
            var jxhr = document.createElement('script');
            jxhr.type = 'text/javascript';
            jxhr.src = '/javascripts/libs/jXHR.js';
            var s = document.getElementsByTagName('script')[0];
            s.parentNode.insertBefore(jxhr, s);
        }

        github.showRepos({
            user: 'yoyzhou',
            count: 0,
            skip_forks: true,
            target: '#gh_repos'
        });
    });
  </script>
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>


<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("pigdooo", 3, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/pigdooo" class="twitter-follow-button" data-show-count="false">Follow @pigdooo</a>
  
</section>



<section class="googleplus">
  <h1>
    <a href="https://plus.google.com/112103441901834600398?rel=author">
      <img src="http://www.google.com/images/icons/ui/gprofile_button-32.png" width="32" height="32">
      Google+
    </a>
  </h1>
</section>



  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2013 - yoyzhou -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'yoyzhou';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
